{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sZHEIiUuPAzG"
   },
   "source": [
    "#Α. Στοιχεία Ομάδας"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A684xsIIdHC6"
   },
   "source": [
    "### **Ομάδα Α46**\n",
    "\n",
    "Μαρκουλέσκου Έλενα-Μπιάνκα  (03115126)\n",
    "\n",
    "Παπασκαρλάτος Αλέξανδρος      (03111097)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "colab_type": "code",
    "id": "CuC1WYreRIzv",
    "outputId": "7c8d5533-fbc0-4b42-b5ef-6ce02ca03e8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (18.1)\n",
      "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.20.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.15.4)\n",
      "Requirement already up-to-date: numpy in /usr/local/lib/python3.6/dist-packages (1.15.4)\n",
      "Requirement already up-to-date: pandas in /usr/local/lib/python3.6/dist-packages (0.23.4)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.15.4)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.7)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n",
      "Requirement already up-to-date: scipy in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.15.4)\n",
      "Requirement already up-to-date: imbalanced-learn in /usr/local/lib/python3.6/dist-packages (0.4.3)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.20.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.15.4)\n",
      "Collecting matplotlib\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/07/16d781df15be30df4acfd536c479268f1208b2dfbc91e9ca5d92c9caf673/matplotlib-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (12.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 12.9MB 2.4MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.15.4)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/a7/88719d132b18300b4369fbffa741841cfd36d1e637e1990f27929945b538/kiwisolver-1.0.1-cp36-cp36m-manylinux1_x86_64.whl (949kB)\n",
      "\u001b[K    100% |████████████████████████████████| 952kB 18.5MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (40.6.2)\n",
      "\u001b[31myellowbrick 0.9 has requirement matplotlib<3.0,>=1.5.1, but you'll have matplotlib 3.0.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: kiwisolver, matplotlib\n",
      "  Found existing installation: matplotlib 2.1.2\n",
      "    Uninstalling matplotlib-2.1.2:\n",
      "      Successfully uninstalled matplotlib-2.1.2\n",
      "Successfully installed kiwisolver-1.0.1 matplotlib-3.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip\n",
    "!pip install -U scikit-learn\n",
    "!pip install -U numpy\n",
    "!pip install -U pandas\n",
    "!pip install -U scipy\n",
    "!pip install -U imbalanced-learn\n",
    "!pip install -U matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6e2N6kWcPPNZ"
   },
   "source": [
    "#Β. Εισαγωγή Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nKcYsyJe2XFF"
   },
   "source": [
    "## Σύντομη περιγραφή\n",
    "Το παρόν dataset έχει τίτλο [Quality Assessment of Digital Colposcopies](http://archive.ics.uci.edu/ml/datasets/Quality+Assessment+of+Digital+Colposcopies#). \n",
    "Πρόκειται για την υποκειμενική εκτίμηση που έκαναν 6 ειδικοί πάνω σε δείγματα ψηφιακών κολποσκοπήσεων και αφορά την ποιότητα αυτών. Τέλος, δίνεται και η ομόφωνη απόφασή τους (**consensus**).\n",
    "\n",
    "Αρχικά η ποιότητα των κολποσκοπήσεων εκτιμήθηκε σε 4 βαθμίδες  (poor, fair, good, excellent) και από αυτά εξήχηθκαν έπειτα δύο διακριτές κλάσεις (bad, good).\n",
    "\n",
    "##Δείγματα, χαρακτηριστικά και κλάσεις\n",
    "\n",
    "To dataset αποτελείται από **287 δείγματα** συνολικά, διαχωρισμένα σε **τρία αρχεία** (Hinselmann, Green, Schiller). Ο **αριθμός των χαρακτηριστικών είναι 62** . Από την περιγραφή του dataset μας δίνεται πως αυτά βρίσκονται στις **62 πρώτες κολώνες** του. Στις **7 τελευταίες κολώνες** δίνεται ξεχωριστά η **εκτίμηση** του καθένα από τους 6 ειδικούς καθώς και το consensus. Συμπεραίνουμε άρα πως το μοντέλο μας θα έπρεπε να κάνει προβλέψεις για 7 targets (experts0,...5, consensus). Παρόλα αυτά, στα πλαίσια του εργαστηρίου θα φτιάξουμε μοντέλο το οποίο θα κάνει προβλέψεις **μόνο για το consensus**, το οποίο βρίσκεται στην τελευταία κολώνα και αποτελείται, όπως αναφέραμε πιο πάνω από **2 κλάσεις, bad, good** (0 και 1 αντίστοιχα).\n",
    "<br>\n",
    "\n",
    "Παρακάτω θα εισάγουμε τα 3 αρχεία για να εξάγουμε περισσότερα συμπεράσματα. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "colab_type": "code",
    "id": "2fXZhtInPxMb",
    "outputId": "cbcb76ae-7546-4fcb-bb0f-30e621e7470a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-1ba646eb-54e0-402e-96f8-1edb3e0d2a81\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-1ba646eb-54e0-402e-96f8-1edb3e0d2a81\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving green.csv to green.csv\n",
      "Saving hinselmann.csv to hinselmann.csv\n",
      "Saving schiller.csv to schiller.csv\n",
      "User uploaded file \"green.csv\" with length 105514 bytes\n",
      "User uploaded file \"hinselmann.csv\" with length 107507 bytes\n",
      "User uploaded file \"schiller.csv\" with length 101675 bytes\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "GVWVbE8-RH9B",
    "outputId": "b2f98db2-88ec-445e-9239-bc03ecebd7b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1year.arff  3year.arff\t5year.arff  hinselmann.csv  schiller.csv\n",
      "2year.arff  4year.arff\tgreen.csv   sample_data     tmp\n"
     ]
    }
   ],
   "source": [
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "riHikFFHSEta"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "colab_type": "code",
    "id": "a9-83lEZX6NG",
    "outputId": "00a4f746-1126-4003-d0c3-d18da1931128"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cervix_area</td>\n",
       "      <td>os_area</td>\n",
       "      <td>walls_area</td>\n",
       "      <td>speculum_area</td>\n",
       "      <td>artifacts_area</td>\n",
       "      <td>cervix_artifacts_area</td>\n",
       "      <td>os_artifacts_area</td>\n",
       "      <td>walls_artifacts_area</td>\n",
       "      <td>speculum_artifacts_area</td>\n",
       "      <td>cervix_specularities_area</td>\n",
       "      <td>os_specularities_area</td>\n",
       "      <td>walls_specularities_area</td>\n",
       "      <td>speculum_specularities_area</td>\n",
       "      <td>specularities_area</td>\n",
       "      <td>area_h_max_diff</td>\n",
       "      <td>rgb_cervix_r_mean</td>\n",
       "      <td>rgb_cervix_r_std</td>\n",
       "      <td>rgb_cervix_r_mean_minus_std</td>\n",
       "      <td>rgb_cervix_r_mean_plus_std</td>\n",
       "      <td>rgb_cervix_g_mean</td>\n",
       "      <td>rgb_cervix_g_std</td>\n",
       "      <td>rgb_cervix_g_mean_minus_std</td>\n",
       "      <td>rgb_cervix_g_mean_plus_std</td>\n",
       "      <td>rgb_cervix_b_mean</td>\n",
       "      <td>rgb_cervix_b_std</td>\n",
       "      <td>rgb_cervix_b_mean_minus_std</td>\n",
       "      <td>rgb_cervix_b_mean_plus_std</td>\n",
       "      <td>rgb_total_r_mean</td>\n",
       "      <td>rgb_total_r_std</td>\n",
       "      <td>rgb_total_r_mean_minus_std</td>\n",
       "      <td>rgb_total_r_mean_plus_std</td>\n",
       "      <td>rgb_total_g_mean</td>\n",
       "      <td>rgb_total_g_std</td>\n",
       "      <td>rgb_total_g_mean_minus_std</td>\n",
       "      <td>rgb_total_g_mean_plus_std</td>\n",
       "      <td>rgb_total_b_mean</td>\n",
       "      <td>rgb_total_b_std</td>\n",
       "      <td>rgb_total_b_mean_minus_std</td>\n",
       "      <td>rgb_total_b_mean_plus_std</td>\n",
       "      <td>hsv_cervix_h_mean</td>\n",
       "      <td>hsv_cervix_h_std</td>\n",
       "      <td>hsv_cervix_s_mean</td>\n",
       "      <td>hsv_cervix_s_std</td>\n",
       "      <td>hsv_cervix_v_mean</td>\n",
       "      <td>hsv_cervix_v_std</td>\n",
       "      <td>hsv_total_h_mean</td>\n",
       "      <td>hsv_total_h_std</td>\n",
       "      <td>hsv_total_s_mean</td>\n",
       "      <td>hsv_total_s_std</td>\n",
       "      <td>hsv_total_v_mean</td>\n",
       "      <td>hsv_total_v_std</td>\n",
       "      <td>fit_cervix_hull_rate</td>\n",
       "      <td>fit_cervix_hull_total</td>\n",
       "      <td>fit_cervix_bbox_rate</td>\n",
       "      <td>fit_cervix_bbox_total</td>\n",
       "      <td>fit_circle_rate</td>\n",
       "      <td>fit_circle_total</td>\n",
       "      <td>fit_ellipse_rate</td>\n",
       "      <td>fit_ellipse_total</td>\n",
       "      <td>fit_ellipse_goodness</td>\n",
       "      <td>dist_to_center_cervix</td>\n",
       "      <td>dist_to_center_os</td>\n",
       "      <td>experts::0</td>\n",
       "      <td>experts::1</td>\n",
       "      <td>experts::2</td>\n",
       "      <td>experts::3</td>\n",
       "      <td>experts::4</td>\n",
       "      <td>experts::5</td>\n",
       "      <td>consensus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.34464664392400002</td>\n",
       "      <td>0.00307978843967</td>\n",
       "      <td>0.047521707791700001</td>\n",
       "      <td>0.28821558158900001</td>\n",
       "      <td>0.17858494299</td>\n",
       "      <td>0.016563880445300001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043499832888200002</td>\n",
       "      <td>0.010149380358000001</td>\n",
       "      <td>0.00013323752771300001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085833120831000004</td>\n",
       "      <td>0.024906935736700001</td>\n",
       "      <td>0.26356037565399998</td>\n",
       "      <td>37.594457745900002</td>\n",
       "      <td>15.7850211066</td>\n",
       "      <td>21.809436639200001</td>\n",
       "      <td>53.3794788525</td>\n",
       "      <td>109.918444622</td>\n",
       "      <td>38.735420721099999</td>\n",
       "      <td>71.183023900699993</td>\n",
       "      <td>148.65386534300001</td>\n",
       "      <td>55.029617806200001</td>\n",
       "      <td>22.1603304048</td>\n",
       "      <td>32.869287401299999</td>\n",
       "      <td>77.189948211000001</td>\n",
       "      <td>38.561367310000001</td>\n",
       "      <td>38.1190589148</td>\n",
       "      <td>0.44230839517199999</td>\n",
       "      <td>76.6804262247</td>\n",
       "      <td>95.109754604200006</td>\n",
       "      <td>51.565052215400002</td>\n",
       "      <td>43.544702388799998</td>\n",
       "      <td>146.67480681999999</td>\n",
       "      <td>48.808474358300003</td>\n",
       "      <td>40.765227547599999</td>\n",
       "      <td>8.0432468107799995</td>\n",
       "      <td>89.573701905899995</td>\n",
       "      <td>5.0146275175500001</td>\n",
       "      <td>2.9919438616699998</td>\n",
       "      <td>167.95277999499999</td>\n",
       "      <td>25.813163448699999</td>\n",
       "      <td>109.91944666099999</td>\n",
       "      <td>38.733740507</td>\n",
       "      <td>5.0908006387200002</td>\n",
       "      <td>2.93664998186</td>\n",
       "      <td>159.486915899</td>\n",
       "      <td>38.437293724100002</td>\n",
       "      <td>95.123888739199998</td>\n",
       "      <td>51.583029462200003</td>\n",
       "      <td>0.92306659438600003</td>\n",
       "      <td>0.37337137539199999</td>\n",
       "      <td>0.84445381807099995</td>\n",
       "      <td>0.40812965321299999</td>\n",
       "      <td>0.60339907973100004</td>\n",
       "      <td>0.57117528929299999</td>\n",
       "      <td>0.96299532207399996</td>\n",
       "      <td>0.35789025764100002</td>\n",
       "      <td>85.474311254499995</td>\n",
       "      <td>0.26593312452500001</td>\n",
       "      <td>0.346293520553</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.16532934808899999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048235596648500002</td>\n",
       "      <td>0.50473589293700005</td>\n",
       "      <td>0.50278296002</td>\n",
       "      <td>0.0070123156652999999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097404510920400006</td>\n",
       "      <td>0.97383731709599997</td>\n",
       "      <td>0.0040551182388799999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054999239233599999</td>\n",
       "      <td>0.028430520180300001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.505882135999997</td>\n",
       "      <td>24.3618774268</td>\n",
       "      <td>35.144004709199997</td>\n",
       "      <td>83.867759562800003</td>\n",
       "      <td>122.36607538</td>\n",
       "      <td>44.742406857600002</td>\n",
       "      <td>77.623668522299994</td>\n",
       "      <td>167.108482237</td>\n",
       "      <td>78.058434134799995</td>\n",
       "      <td>30.818728555300002</td>\n",
       "      <td>47.239705579499997</td>\n",
       "      <td>108.87716269000001</td>\n",
       "      <td>54.9324671826</td>\n",
       "      <td>39.447415318899999</td>\n",
       "      <td>15.485051863700001</td>\n",
       "      <td>94.379882501500006</td>\n",
       "      <td>101.680458954</td>\n",
       "      <td>46.028851997499999</td>\n",
       "      <td>55.6516069563</td>\n",
       "      <td>147.70931095099999</td>\n",
       "      <td>63.218930618100003</td>\n",
       "      <td>43.925911883200001</td>\n",
       "      <td>19.293018735</td>\n",
       "      <td>107.144842501</td>\n",
       "      <td>4.9443818879399997</td>\n",
       "      <td>2.9651080245000001</td>\n",
       "      <td>130.26049196</td>\n",
       "      <td>24.143867452399999</td>\n",
       "      <td>122.36664699799999</td>\n",
       "      <td>44.743931739200001</td>\n",
       "      <td>5.0800633497199996</td>\n",
       "      <td>2.8941625628200001</td>\n",
       "      <td>128.251977616</td>\n",
       "      <td>33.000693045200002</td>\n",
       "      <td>101.725518588</td>\n",
       "      <td>46.093510496999997</td>\n",
       "      <td>0.85086059253500002</td>\n",
       "      <td>0.19430838557999999</td>\n",
       "      <td>0.64664467748400001</td>\n",
       "      <td>0.25567263420800002</td>\n",
       "      <td>0.49731536549200001</td>\n",
       "      <td>0.33244367570599997</td>\n",
       "      <td>0.89462493629700002</td>\n",
       "      <td>0.18480297315800001</td>\n",
       "      <td>124.79412873299999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.283059065005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.45701048101500003</td>\n",
       "      <td>0.0016811833471599999</td>\n",
       "      <td>0.242887859003</td>\n",
       "      <td>0.212859459517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00175571277825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083055499375300004</td>\n",
       "      <td>0.018591423393399999</td>\n",
       "      <td>0.26979754243300003</td>\n",
       "      <td>39.353850780199998</td>\n",
       "      <td>19.417332039800002</td>\n",
       "      <td>19.9365187404</td>\n",
       "      <td>58.77118282</td>\n",
       "      <td>109.54338601400001</td>\n",
       "      <td>49.7534903329</td>\n",
       "      <td>59.789895680699999</td>\n",
       "      <td>159.296876346</td>\n",
       "      <td>54.642888168699997</td>\n",
       "      <td>27.7819646867</td>\n",
       "      <td>26.860923481899999</td>\n",
       "      <td>82.424852855400005</td>\n",
       "      <td>41.242230358500002</td>\n",
       "      <td>34.196355730599997</td>\n",
       "      <td>7.04587462799</td>\n",
       "      <td>75.438586089099999</td>\n",
       "      <td>109.592341791</td>\n",
       "      <td>57.576639909699999</td>\n",
       "      <td>52.015701880999998</td>\n",
       "      <td>167.16898169999999</td>\n",
       "      <td>53.470240865000001</td>\n",
       "      <td>38.344390770499999</td>\n",
       "      <td>15.125850094500001</td>\n",
       "      <td>91.814631635500007</td>\n",
       "      <td>5.0499460040799997</td>\n",
       "      <td>2.9839661516799998</td>\n",
       "      <td>163.57697884999999</td>\n",
       "      <td>24.973041630099999</td>\n",
       "      <td>109.544201276</td>\n",
       "      <td>49.753658982200001</td>\n",
       "      <td>5.0789362477899997</td>\n",
       "      <td>2.9680230645500001</td>\n",
       "      <td>162.268658773</td>\n",
       "      <td>33.590791987899998</td>\n",
       "      <td>109.597126641</td>\n",
       "      <td>57.5845151081</td>\n",
       "      <td>0.91851433089599999</td>\n",
       "      <td>0.49755400176300002</td>\n",
       "      <td>0.74744260036800003</td>\n",
       "      <td>0.61143221003100001</td>\n",
       "      <td>0.63392451284499995</td>\n",
       "      <td>0.720922557425</td>\n",
       "      <td>0.920286628238</td>\n",
       "      <td>0.49659580721000002</td>\n",
       "      <td>94.948697093199996</td>\n",
       "      <td>0.51873979071599996</td>\n",
       "      <td>0.41937512460600002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.51324386582600001</td>\n",
       "      <td>0.0057110268186399997</td>\n",
       "      <td>0.213780870156</td>\n",
       "      <td>0.25181918305099998</td>\n",
       "      <td>0.079795126563599994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017594461617400001</td>\n",
       "      <td>0.0072077640894999996</td>\n",
       "      <td>0.0012883662631600001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00031503818785100002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00072859521943600004</td>\n",
       "      <td>0.107021600812</td>\n",
       "      <td>46.322391384600003</td>\n",
       "      <td>17.711957371099999</td>\n",
       "      <td>28.610434013500001</td>\n",
       "      <td>64.034348755699995</td>\n",
       "      <td>116.075086666</td>\n",
       "      <td>43.593124495799998</td>\n",
       "      <td>72.481962170200006</td>\n",
       "      <td>159.66821116200001</td>\n",
       "      <td>51.4309233647</td>\n",
       "      <td>18.573016382799999</td>\n",
       "      <td>32.857906981900001</td>\n",
       "      <td>70.003939747399997</td>\n",
       "      <td>40.365564998000004</td>\n",
       "      <td>17.2590870268</td>\n",
       "      <td>23.1064779712</td>\n",
       "      <td>57.6246520248</td>\n",
       "      <td>102.64185871399999</td>\n",
       "      <td>38.606995469899999</td>\n",
       "      <td>64.034863243800004</td>\n",
       "      <td>141.24885418400001</td>\n",
       "      <td>50.8052048638</td>\n",
       "      <td>18.072100981199998</td>\n",
       "      <td>32.733103882599998</td>\n",
       "      <td>68.877305845099997</td>\n",
       "      <td>5.17765422047</td>\n",
       "      <td>2.9692140468099999</td>\n",
       "      <td>156.24275401200001</td>\n",
       "      <td>25.499379130000001</td>\n",
       "      <td>116.081769772</td>\n",
       "      <td>43.582671078200001</td>\n",
       "      <td>5.0718790076399998</td>\n",
       "      <td>2.9090019641799998</td>\n",
       "      <td>158.34394592500001</td>\n",
       "      <td>28.2739276352</td>\n",
       "      <td>102.648278311</td>\n",
       "      <td>38.598299984999997</td>\n",
       "      <td>0.95171001660599996</td>\n",
       "      <td>0.539285976685</td>\n",
       "      <td>0.85540906172800002</td>\n",
       "      <td>0.59999816320499999</td>\n",
       "      <td>0.61813971545900004</td>\n",
       "      <td>0.83030397981399995</td>\n",
       "      <td>0.96461084684200005</td>\n",
       "      <td>0.53207349627699996</td>\n",
       "      <td>74.221670202599995</td>\n",
       "      <td>0.34720221604399998</td>\n",
       "      <td>0.36167198654999999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                      1     ...              67         68\n",
       "0          cervix_area                os_area    ...      experts::5  consensus\n",
       "1  0.34464664392400002       0.00307978843967    ...             1.0        1.0\n",
       "2  0.16532934808899999                    0.0    ...             0.0        0.0\n",
       "3  0.45701048101500003  0.0016811833471599999    ...             0.0        0.0\n",
       "4  0.51324386582600001  0.0057110268186399997    ...             1.0        1.0\n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.read_csv(\"green.csv\", header=None)).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "colab_type": "code",
    "id": "g65LJYSXYbaU",
    "outputId": "f63fcf56-91a0-4316-8f7f-9b30060e54c2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cervix_area</td>\n",
       "      <td>os_area</td>\n",
       "      <td>walls_area</td>\n",
       "      <td>speculum_area</td>\n",
       "      <td>artifacts_area</td>\n",
       "      <td>cervix_artifacts_area</td>\n",
       "      <td>os_artifacts_area</td>\n",
       "      <td>walls_artifacts_area</td>\n",
       "      <td>speculum_artifacts_area</td>\n",
       "      <td>cervix_specularities_area</td>\n",
       "      <td>os_specularities_area</td>\n",
       "      <td>walls_specularities_area</td>\n",
       "      <td>speculum_specularities_area</td>\n",
       "      <td>specularities_area</td>\n",
       "      <td>area_h_max_diff</td>\n",
       "      <td>rgb_cervix_r_mean</td>\n",
       "      <td>rgb_cervix_r_std</td>\n",
       "      <td>rgb_cervix_r_mean_minus_std</td>\n",
       "      <td>rgb_cervix_r_mean_plus_std</td>\n",
       "      <td>rgb_cervix_g_mean</td>\n",
       "      <td>rgb_cervix_g_std</td>\n",
       "      <td>rgb_cervix_g_mean_minus_std</td>\n",
       "      <td>rgb_cervix_g_mean_plus_std</td>\n",
       "      <td>rgb_cervix_b_mean</td>\n",
       "      <td>rgb_cervix_b_std</td>\n",
       "      <td>rgb_cervix_b_mean_minus_std</td>\n",
       "      <td>rgb_cervix_b_mean_plus_std</td>\n",
       "      <td>rgb_total_r_mean</td>\n",
       "      <td>rgb_total_r_std</td>\n",
       "      <td>rgb_total_r_mean_minus_std</td>\n",
       "      <td>rgb_total_r_mean_plus_std</td>\n",
       "      <td>rgb_total_g_mean</td>\n",
       "      <td>rgb_total_g_std</td>\n",
       "      <td>rgb_total_g_mean_minus_std</td>\n",
       "      <td>rgb_total_g_mean_plus_std</td>\n",
       "      <td>rgb_total_b_mean</td>\n",
       "      <td>rgb_total_b_std</td>\n",
       "      <td>rgb_total_b_mean_minus_std</td>\n",
       "      <td>rgb_total_b_mean_plus_std</td>\n",
       "      <td>hsv_cervix_h_mean</td>\n",
       "      <td>hsv_cervix_h_std</td>\n",
       "      <td>hsv_cervix_s_mean</td>\n",
       "      <td>hsv_cervix_s_std</td>\n",
       "      <td>hsv_cervix_v_mean</td>\n",
       "      <td>hsv_cervix_v_std</td>\n",
       "      <td>hsv_total_h_mean</td>\n",
       "      <td>hsv_total_h_std</td>\n",
       "      <td>hsv_total_s_mean</td>\n",
       "      <td>hsv_total_s_std</td>\n",
       "      <td>hsv_total_v_mean</td>\n",
       "      <td>hsv_total_v_std</td>\n",
       "      <td>fit_cervix_hull_rate</td>\n",
       "      <td>fit_cervix_hull_total</td>\n",
       "      <td>fit_cervix_bbox_rate</td>\n",
       "      <td>fit_cervix_bbox_total</td>\n",
       "      <td>fit_circle_rate</td>\n",
       "      <td>fit_circle_total</td>\n",
       "      <td>fit_ellipse_rate</td>\n",
       "      <td>fit_ellipse_total</td>\n",
       "      <td>fit_ellipse_goodness</td>\n",
       "      <td>dist_to_center_cervix</td>\n",
       "      <td>dist_to_center_os</td>\n",
       "      <td>experts::0</td>\n",
       "      <td>experts::1</td>\n",
       "      <td>experts::2</td>\n",
       "      <td>experts::3</td>\n",
       "      <td>experts::4</td>\n",
       "      <td>experts::5</td>\n",
       "      <td>consensus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.33465207987599999</td>\n",
       "      <td>0.0027274720134899998</td>\n",
       "      <td>0.054514793280200001</td>\n",
       "      <td>0.26521354598899999</td>\n",
       "      <td>0.16595531090599999</td>\n",
       "      <td>0.0062665538990200002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034324216119400001</td>\n",
       "      <td>0.0090773099074400003</td>\n",
       "      <td>0.0013813151627000001</td>\n",
       "      <td>0.0042387242452400003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13712037720100001</td>\n",
       "      <td>0.037418568769600001</td>\n",
       "      <td>0.347649995652</td>\n",
       "      <td>136.60196477299999</td>\n",
       "      <td>46.272693181000001</td>\n",
       "      <td>90.329271591799994</td>\n",
       "      <td>182.87465795400001</td>\n",
       "      <td>82.407184099399998</td>\n",
       "      <td>26.533505960700001</td>\n",
       "      <td>55.873678138700001</td>\n",
       "      <td>108.94069005999999</td>\n",
       "      <td>196.65247056000001</td>\n",
       "      <td>63.572919948699997</td>\n",
       "      <td>133.07955061199999</td>\n",
       "      <td>260.22539050900002</td>\n",
       "      <td>110.241465027</td>\n",
       "      <td>56.944859397400002</td>\n",
       "      <td>53.296605630000002</td>\n",
       "      <td>167.18632442500001</td>\n",
       "      <td>76.407073496300001</td>\n",
       "      <td>44.545685535499999</td>\n",
       "      <td>31.861387960799998</td>\n",
       "      <td>120.952759032</td>\n",
       "      <td>136.57977199300001</td>\n",
       "      <td>73.100204893599994</td>\n",
       "      <td>63.479567098899999</td>\n",
       "      <td>209.67997688599999</td>\n",
       "      <td>4.4259734613999999</td>\n",
       "      <td>3.0060954394900001</td>\n",
       "      <td>143.65735056700001</td>\n",
       "      <td>25.751500211700002</td>\n",
       "      <td>196.80262881799999</td>\n",
       "      <td>63.312714341899998</td>\n",
       "      <td>4.2436787519300001</td>\n",
       "      <td>2.7857349037099999</td>\n",
       "      <td>106.671553561</td>\n",
       "      <td>39.278662184700003</td>\n",
       "      <td>139.00113575099999</td>\n",
       "      <td>72.477167508199997</td>\n",
       "      <td>0.89269704876800005</td>\n",
       "      <td>0.37487754702199999</td>\n",
       "      <td>0.81125127869299996</td>\n",
       "      <td>0.41251346982800002</td>\n",
       "      <td>0.58085056797099999</td>\n",
       "      <td>0.57614143521500005</td>\n",
       "      <td>0.94722252379799998</td>\n",
       "      <td>0.35329827096400002</td>\n",
       "      <td>100.911343444</td>\n",
       "      <td>0.25645475298999998</td>\n",
       "      <td>0.40425719991999998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.44133214193800002</td>\n",
       "      <td>0.00239289926394</td>\n",
       "      <td>0.157184232186</td>\n",
       "      <td>0.204246273108</td>\n",
       "      <td>0.052486419724599997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.31596784515499998</td>\n",
       "      <td>0.0031774228407599999</td>\n",
       "      <td>0.010092958806900001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097199056330499994</td>\n",
       "      <td>0.027827439263299999</td>\n",
       "      <td>0.27828327729699998</td>\n",
       "      <td>129.52626948400001</td>\n",
       "      <td>59.3369026361</td>\n",
       "      <td>70.189366847700001</td>\n",
       "      <td>188.86317212</td>\n",
       "      <td>73.982133702799999</td>\n",
       "      <td>34.630387928600001</td>\n",
       "      <td>39.351745774199998</td>\n",
       "      <td>108.61252163100001</td>\n",
       "      <td>156.66128853500001</td>\n",
       "      <td>72.376620738400007</td>\n",
       "      <td>84.284667796400001</td>\n",
       "      <td>229.037909273</td>\n",
       "      <td>133.55119452900001</td>\n",
       "      <td>63.423112420599999</td>\n",
       "      <td>70.128082108200005</td>\n",
       "      <td>196.97430694900001</td>\n",
       "      <td>83.515205598600005</td>\n",
       "      <td>45.088412311799999</td>\n",
       "      <td>38.426793286799999</td>\n",
       "      <td>128.60361791</td>\n",
       "      <td>141.22207766</td>\n",
       "      <td>67.361492169200005</td>\n",
       "      <td>73.860585490399998</td>\n",
       "      <td>208.583569829</td>\n",
       "      <td>4.1876824207199999</td>\n",
       "      <td>2.9460254341100001</td>\n",
       "      <td>130.104648424</td>\n",
       "      <td>24.989313293399999</td>\n",
       "      <td>157.55281607200001</td>\n",
       "      <td>71.732135507699994</td>\n",
       "      <td>3.9525997614900001</td>\n",
       "      <td>2.82463090741</td>\n",
       "      <td>108.819320631</td>\n",
       "      <td>30.646155881199999</td>\n",
       "      <td>147.697599309</td>\n",
       "      <td>68.707443448199996</td>\n",
       "      <td>0.97352713430799998</td>\n",
       "      <td>0.453333170063</td>\n",
       "      <td>0.87690871141600002</td>\n",
       "      <td>0.50328173981199997</td>\n",
       "      <td>0.65817966734</td>\n",
       "      <td>0.670534451059</td>\n",
       "      <td>0.96624525574300002</td>\n",
       "      <td>0.45674960814999999</td>\n",
       "      <td>65.515920452700001</td>\n",
       "      <td>0.56675882468500005</td>\n",
       "      <td>0.49179095694899999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.48632253058000002</td>\n",
       "      <td>0.017873068604400001</td>\n",
       "      <td>0.21171130678</td>\n",
       "      <td>0.24566183913799999</td>\n",
       "      <td>0.039998364892600002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0031679657517</td>\n",
       "      <td>0.0015631656080300001</td>\n",
       "      <td>0.00366359919331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000954353439438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0024521208855799999</td>\n",
       "      <td>0.078269102555699993</td>\n",
       "      <td>113.9087868</td>\n",
       "      <td>46.3955796642</td>\n",
       "      <td>67.513207136099993</td>\n",
       "      <td>160.304366464</td>\n",
       "      <td>67.348045072100007</td>\n",
       "      <td>30.9462950779</td>\n",
       "      <td>36.401749994200003</td>\n",
       "      <td>98.294340150099998</td>\n",
       "      <td>191.46769873100001</td>\n",
       "      <td>51.538431738900002</td>\n",
       "      <td>139.92926699200001</td>\n",
       "      <td>243.00613046999999</td>\n",
       "      <td>101.608208635</td>\n",
       "      <td>41.392987175800002</td>\n",
       "      <td>60.215221459600002</td>\n",
       "      <td>143.001195811</td>\n",
       "      <td>61.537657352099998</td>\n",
       "      <td>26.7999896816</td>\n",
       "      <td>34.737667670500002</td>\n",
       "      <td>88.337647033600007</td>\n",
       "      <td>183.92700578</td>\n",
       "      <td>53.077406463300001</td>\n",
       "      <td>130.849599316</td>\n",
       "      <td>237.00441224299999</td>\n",
       "      <td>4.5666041137600004</td>\n",
       "      <td>3.0474424408299998</td>\n",
       "      <td>167.33328093399999</td>\n",
       "      <td>23.277554902399999</td>\n",
       "      <td>191.471804771</td>\n",
       "      <td>51.543287170200003</td>\n",
       "      <td>4.6110911329600004</td>\n",
       "      <td>3.0469366721900002</td>\n",
       "      <td>170.203128061</td>\n",
       "      <td>21.391209266699999</td>\n",
       "      <td>183.92995689700001</td>\n",
       "      <td>53.080447602500001</td>\n",
       "      <td>0.94641310982100002</td>\n",
       "      <td>0.51385861579199998</td>\n",
       "      <td>0.87596246339499995</td>\n",
       "      <td>0.555186495886</td>\n",
       "      <td>0.60408767731799995</td>\n",
       "      <td>0.80505289023399995</td>\n",
       "      <td>0.964173828766</td>\n",
       "      <td>0.50439300058799996</td>\n",
       "      <td>84.437573652799998</td>\n",
       "      <td>0.46657497127199998</td>\n",
       "      <td>0.49192822967099997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.38383883603399999</td>\n",
       "      <td>0.00663631513538</td>\n",
       "      <td>0.15849958125899999</td>\n",
       "      <td>0.37785092142299997</td>\n",
       "      <td>0.046452513215300001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010740700456799999</td>\n",
       "      <td>0.0136568160454</td>\n",
       "      <td>0.00153518321597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00062601381668899998</td>\n",
       "      <td>0.0910526208433</td>\n",
       "      <td>0.035067471590899998</td>\n",
       "      <td>0.46835670684500003</td>\n",
       "      <td>144.46739779699999</td>\n",
       "      <td>47.2306571154</td>\n",
       "      <td>97.236740681699999</td>\n",
       "      <td>191.698054912</td>\n",
       "      <td>81.794487053899999</td>\n",
       "      <td>28.266595368099999</td>\n",
       "      <td>53.5278916858</td>\n",
       "      <td>110.061082422</td>\n",
       "      <td>203.30888267700001</td>\n",
       "      <td>54.882225523499997</td>\n",
       "      <td>148.42665715300001</td>\n",
       "      <td>258.19110819999997</td>\n",
       "      <td>121.085288499</td>\n",
       "      <td>53.945306397400003</td>\n",
       "      <td>67.139982101800001</td>\n",
       "      <td>175.03059489699999</td>\n",
       "      <td>77.969392878099995</td>\n",
       "      <td>43.222269879199999</td>\n",
       "      <td>34.747122998999998</td>\n",
       "      <td>121.191662757</td>\n",
       "      <td>144.94095623499999</td>\n",
       "      <td>71.810005288400006</td>\n",
       "      <td>73.130950946900001</td>\n",
       "      <td>216.75096152399999</td>\n",
       "      <td>4.3990783217500002</td>\n",
       "      <td>3.0137033781999998</td>\n",
       "      <td>150.942409545</td>\n",
       "      <td>23.2355986112</td>\n",
       "      <td>203.40787199600001</td>\n",
       "      <td>54.898264960699997</td>\n",
       "      <td>4.0888373171000003</td>\n",
       "      <td>2.7485921419400001</td>\n",
       "      <td>114.390621939</td>\n",
       "      <td>40.8996766761</td>\n",
       "      <td>149.19534311300001</td>\n",
       "      <td>69.817581123799997</td>\n",
       "      <td>0.94210791974899999</td>\n",
       "      <td>0.40742554858899999</td>\n",
       "      <td>0.87996897115200001</td>\n",
       "      <td>0.43619587578399999</td>\n",
       "      <td>0.58811549976800004</td>\n",
       "      <td>0.65265893550800003</td>\n",
       "      <td>0.96119635726599995</td>\n",
       "      <td>0.39933446806400003</td>\n",
       "      <td>66.491784714800005</td>\n",
       "      <td>0.371283043388</td>\n",
       "      <td>0.63237456964000005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                      1     ...              67         68\n",
       "0          cervix_area                os_area    ...      experts::5  consensus\n",
       "1  0.33465207987599999  0.0027274720134899998    ...             1.0        1.0\n",
       "2  0.44133214193800002       0.00239289926394    ...             1.0        1.0\n",
       "3  0.48632253058000002   0.017873068604400001    ...             1.0        1.0\n",
       "4  0.38383883603399999       0.00663631513538    ...             1.0        1.0\n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.read_csv(\"hinselmann.csv\", header=None)).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "colab_type": "code",
    "id": "pOYZIneYYbm-",
    "outputId": "dcaaf688-38fe-4288-87b5-8ab8c818e1e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cervix_area</td>\n",
       "      <td>os_area</td>\n",
       "      <td>walls_area</td>\n",
       "      <td>speculum_area</td>\n",
       "      <td>artifacts_area</td>\n",
       "      <td>cervix_artifacts_area</td>\n",
       "      <td>os_artifacts_area</td>\n",
       "      <td>walls_artifacts_area</td>\n",
       "      <td>speculum_artifacts_area</td>\n",
       "      <td>cervix_specularities_area</td>\n",
       "      <td>os_specularities_area</td>\n",
       "      <td>walls_specularities_area</td>\n",
       "      <td>speculum_specularities_area</td>\n",
       "      <td>specularities_area</td>\n",
       "      <td>area_h_max_diff</td>\n",
       "      <td>rgb_cervix_r_mean</td>\n",
       "      <td>rgb_cervix_r_std</td>\n",
       "      <td>rgb_cervix_r_mean_minus_std</td>\n",
       "      <td>rgb_cervix_r_mean_plus_std</td>\n",
       "      <td>rgb_cervix_g_mean</td>\n",
       "      <td>rgb_cervix_g_std</td>\n",
       "      <td>rgb_cervix_g_mean_minus_std</td>\n",
       "      <td>rgb_cervix_g_mean_plus_std</td>\n",
       "      <td>rgb_cervix_b_mean</td>\n",
       "      <td>rgb_cervix_b_std</td>\n",
       "      <td>rgb_cervix_b_mean_minus_std</td>\n",
       "      <td>rgb_cervix_b_mean_plus_std</td>\n",
       "      <td>rgb_total_r_mean</td>\n",
       "      <td>rgb_total_r_std</td>\n",
       "      <td>rgb_total_r_mean_minus_std</td>\n",
       "      <td>rgb_total_r_mean_plus_std</td>\n",
       "      <td>rgb_total_g_mean</td>\n",
       "      <td>rgb_total_g_std</td>\n",
       "      <td>rgb_total_g_mean_minus_std</td>\n",
       "      <td>rgb_total_g_mean_plus_std</td>\n",
       "      <td>rgb_total_b_mean</td>\n",
       "      <td>rgb_total_b_std</td>\n",
       "      <td>rgb_total_b_mean_minus_std</td>\n",
       "      <td>rgb_total_b_mean_plus_std</td>\n",
       "      <td>hsv_cervix_h_mean</td>\n",
       "      <td>hsv_cervix_h_std</td>\n",
       "      <td>hsv_cervix_s_mean</td>\n",
       "      <td>hsv_cervix_s_std</td>\n",
       "      <td>hsv_cervix_v_mean</td>\n",
       "      <td>hsv_cervix_v_std</td>\n",
       "      <td>hsv_total_h_mean</td>\n",
       "      <td>hsv_total_h_std</td>\n",
       "      <td>hsv_total_s_mean</td>\n",
       "      <td>hsv_total_s_std</td>\n",
       "      <td>hsv_total_v_mean</td>\n",
       "      <td>hsv_total_v_std</td>\n",
       "      <td>fit_cervix_hull_rate</td>\n",
       "      <td>fit_cervix_hull_total</td>\n",
       "      <td>fit_cervix_bbox_rate</td>\n",
       "      <td>fit_cervix_bbox_total</td>\n",
       "      <td>fit_circle_rate</td>\n",
       "      <td>fit_circle_total</td>\n",
       "      <td>fit_ellipse_rate</td>\n",
       "      <td>fit_ellipse_total</td>\n",
       "      <td>fit_ellipse_goodness</td>\n",
       "      <td>dist_to_center_cervix</td>\n",
       "      <td>dist_to_center_os</td>\n",
       "      <td>experts::0</td>\n",
       "      <td>experts::1</td>\n",
       "      <td>experts::2</td>\n",
       "      <td>experts::3</td>\n",
       "      <td>experts::4</td>\n",
       "      <td>experts::5</td>\n",
       "      <td>consensus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.31789887977100001</td>\n",
       "      <td>0.0089747948552500005</td>\n",
       "      <td>0.142670408926</td>\n",
       "      <td>0.264625303491</td>\n",
       "      <td>0.051382181987200001</td>\n",
       "      <td>0.022907455980500001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00029148295064599999</td>\n",
       "      <td>0.016850305281999999</td>\n",
       "      <td>0.0033511942849800001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204350736266</td>\n",
       "      <td>0.056411025666099998</td>\n",
       "      <td>0.300466440625</td>\n",
       "      <td>72.560894788400006</td>\n",
       "      <td>19.990110418499999</td>\n",
       "      <td>52.570784369899997</td>\n",
       "      <td>92.551005206900001</td>\n",
       "      <td>56.272374512600003</td>\n",
       "      <td>17.064522756599999</td>\n",
       "      <td>39.207851755900002</td>\n",
       "      <td>73.336897269199994</td>\n",
       "      <td>84.614134506400006</td>\n",
       "      <td>27.884325480499999</td>\n",
       "      <td>56.729809025900003</td>\n",
       "      <td>112.498459987</td>\n",
       "      <td>101.685678512</td>\n",
       "      <td>55.1033100613</td>\n",
       "      <td>46.582368450700002</td>\n",
       "      <td>156.78898857300001</td>\n",
       "      <td>80.899135482000005</td>\n",
       "      <td>50.606872707500003</td>\n",
       "      <td>30.292262774499999</td>\n",
       "      <td>131.506008189</td>\n",
       "      <td>113.311731608</td>\n",
       "      <td>61.0889886593</td>\n",
       "      <td>52.222742948200001</td>\n",
       "      <td>174.400720267</td>\n",
       "      <td>4.1559179824100001</td>\n",
       "      <td>2.6913199964199999</td>\n",
       "      <td>87.297616074700002</td>\n",
       "      <td>27.363927797799999</td>\n",
       "      <td>87.261473000699993</td>\n",
       "      <td>26.895496298800001</td>\n",
       "      <td>4.1128134519000001</td>\n",
       "      <td>2.54292365992</td>\n",
       "      <td>81.272271135400004</td>\n",
       "      <td>32.118904383199997</td>\n",
       "      <td>118.526991698</td>\n",
       "      <td>61.029658228800002</td>\n",
       "      <td>0.94214821693499995</td>\n",
       "      <td>0.33741918103399998</td>\n",
       "      <td>0.83217996129799998</td>\n",
       "      <td>0.38200737166900001</td>\n",
       "      <td>0.61186896917199995</td>\n",
       "      <td>0.51955385186699998</td>\n",
       "      <td>0.96493654785600003</td>\n",
       "      <td>0.32945055348699998</td>\n",
       "      <td>178.01931911599999</td>\n",
       "      <td>0.327891145853</td>\n",
       "      <td>0.48670198897400002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.55102782467800004</td>\n",
       "      <td>0.0075833088427399997</td>\n",
       "      <td>0.096114110808900005</td>\n",
       "      <td>0.24142282917300001</td>\n",
       "      <td>0.056712884262200003</td>\n",
       "      <td>0.012370019564000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132462549544</td>\n",
       "      <td>0.039886493519500001</td>\n",
       "      <td>0.0036945153566000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090613736094199995</td>\n",
       "      <td>0.02391200529</td>\n",
       "      <td>0.067048389316599996</td>\n",
       "      <td>46.969042376799997</td>\n",
       "      <td>25.381677097400001</td>\n",
       "      <td>21.5873652794</td>\n",
       "      <td>72.350719474200005</td>\n",
       "      <td>35.246707078299998</td>\n",
       "      <td>18.2114880946</td>\n",
       "      <td>17.035218983699998</td>\n",
       "      <td>53.458195172899998</td>\n",
       "      <td>58.901680984499997</td>\n",
       "      <td>32.791009959199997</td>\n",
       "      <td>26.1106710253</td>\n",
       "      <td>91.692690943800002</td>\n",
       "      <td>75.461672217900002</td>\n",
       "      <td>57.0598953573</td>\n",
       "      <td>18.401776860599998</td>\n",
       "      <td>132.52156757500001</td>\n",
       "      <td>57.700443279799998</td>\n",
       "      <td>45.906089644700003</td>\n",
       "      <td>11.7943536351</td>\n",
       "      <td>103.60653292400001</td>\n",
       "      <td>84.187331627199995</td>\n",
       "      <td>57.111269029500001</td>\n",
       "      <td>27.076062597699998</td>\n",
       "      <td>141.29860065700001</td>\n",
       "      <td>4.3259548643099999</td>\n",
       "      <td>2.3516886013599998</td>\n",
       "      <td>101.32798331799999</td>\n",
       "      <td>41.730324357999997</td>\n",
       "      <td>62.930215017400002</td>\n",
       "      <td>32.303186777599997</td>\n",
       "      <td>4.1481344265000004</td>\n",
       "      <td>2.4519212934999999</td>\n",
       "      <td>91.1974064459</td>\n",
       "      <td>38.062851329600001</td>\n",
       "      <td>88.821760506499999</td>\n",
       "      <td>57.356268716099997</td>\n",
       "      <td>0.89766226852599995</td>\n",
       "      <td>0.61384759502399999</td>\n",
       "      <td>0.82364711122199996</td>\n",
       "      <td>0.66900960031300005</td>\n",
       "      <td>0.64077036632399997</td>\n",
       "      <td>0.85994586147800001</td>\n",
       "      <td>0.970143503676</td>\n",
       "      <td>0.56798589341700001</td>\n",
       "      <td>86.659527428800004</td>\n",
       "      <td>0.57022291094499999</td>\n",
       "      <td>0.53290725482000001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.57013533935299998</td>\n",
       "      <td>0.0085532084601100001</td>\n",
       "      <td>0.21217080557699999</td>\n",
       "      <td>0.26268240691700001</td>\n",
       "      <td>0.052376992381999998</td>\n",
       "      <td>0.015784514377699999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021698158420299998</td>\n",
       "      <td>0.0105019805098</td>\n",
       "      <td>0.0020457679703000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0033618602485799998</td>\n",
       "      <td>0.00019811953257499999</td>\n",
       "      <td>0.0031103056426299998</td>\n",
       "      <td>0.053062363358799998</td>\n",
       "      <td>42.371042348899998</td>\n",
       "      <td>17.401836632799998</td>\n",
       "      <td>24.969205716200001</td>\n",
       "      <td>59.772878981700003</td>\n",
       "      <td>30.377710123300002</td>\n",
       "      <td>13.2177517378</td>\n",
       "      <td>17.159958385500001</td>\n",
       "      <td>43.5954618612</td>\n",
       "      <td>62.908623619099998</td>\n",
       "      <td>20.9572951267</td>\n",
       "      <td>41.951328492499997</td>\n",
       "      <td>83.865918745800002</td>\n",
       "      <td>69.803983395399996</td>\n",
       "      <td>43.8149200322</td>\n",
       "      <td>25.9890633632</td>\n",
       "      <td>113.618903428</td>\n",
       "      <td>45.707416976899999</td>\n",
       "      <td>26.629182197900001</td>\n",
       "      <td>19.078234778999999</td>\n",
       "      <td>72.3365991748</td>\n",
       "      <td>121.205849579</td>\n",
       "      <td>79.048550092799999</td>\n",
       "      <td>42.157299485999999</td>\n",
       "      <td>200.25439967200001</td>\n",
       "      <td>4.4732668233800004</td>\n",
       "      <td>2.8931103255599999</td>\n",
       "      <td>129.189232938</td>\n",
       "      <td>25.850224611800002</td>\n",
       "      <td>63.232991547399998</td>\n",
       "      <td>21.569742308799999</td>\n",
       "      <td>4.5419783041699997</td>\n",
       "      <td>2.94717528828</td>\n",
       "      <td>146.21487436300001</td>\n",
       "      <td>31.481975010900001</td>\n",
       "      <td>121.39625477600001</td>\n",
       "      <td>79.007066038000005</td>\n",
       "      <td>0.90017946450700004</td>\n",
       "      <td>0.633357415752</td>\n",
       "      <td>0.78163955164300003</td>\n",
       "      <td>0.72940953174000001</td>\n",
       "      <td>0.57728743488099998</td>\n",
       "      <td>0.98761085882699995</td>\n",
       "      <td>0.94408208797000004</td>\n",
       "      <td>0.60390441320499999</td>\n",
       "      <td>101.94039188399999</td>\n",
       "      <td>0.51713199876000004</td>\n",
       "      <td>0.55494085596499998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.45640276609300001</td>\n",
       "      <td>0.0069229751559700004</td>\n",
       "      <td>0.11876339779599999</td>\n",
       "      <td>0.372608085162</td>\n",
       "      <td>0.0470793163954</td>\n",
       "      <td>0.010110421599900001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0099449410411799992</td>\n",
       "      <td>0.029686305869999999</td>\n",
       "      <td>0.0051110146223900003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0103918376721</td>\n",
       "      <td>0.14445259952200001</td>\n",
       "      <td>0.057396772139500001</td>\n",
       "      <td>0.461644334923</td>\n",
       "      <td>63.525568562300002</td>\n",
       "      <td>23.715460974900001</td>\n",
       "      <td>39.810107587499999</td>\n",
       "      <td>87.241029537200006</td>\n",
       "      <td>47.450543783999997</td>\n",
       "      <td>19.834743877299999</td>\n",
       "      <td>27.615799906700001</td>\n",
       "      <td>67.285287661300003</td>\n",
       "      <td>87.799416034900005</td>\n",
       "      <td>41.5341820501</td>\n",
       "      <td>46.265233984799998</td>\n",
       "      <td>129.33359808500001</td>\n",
       "      <td>95.577849480799998</td>\n",
       "      <td>57.639912478900001</td>\n",
       "      <td>37.937937001900004</td>\n",
       "      <td>153.21776195999999</td>\n",
       "      <td>73.231090198900006</td>\n",
       "      <td>52.571685491499998</td>\n",
       "      <td>20.6594047074</td>\n",
       "      <td>125.80277569</td>\n",
       "      <td>106.88467684699999</td>\n",
       "      <td>59.211378056999997</td>\n",
       "      <td>47.673298789599997</td>\n",
       "      <td>166.096054904</td>\n",
       "      <td>4.35213494045</td>\n",
       "      <td>2.62065065603</td>\n",
       "      <td>106.944463047</td>\n",
       "      <td>45.023801178100001</td>\n",
       "      <td>90.188114435700001</td>\n",
       "      <td>39.869723851899998</td>\n",
       "      <td>4.0546592818500002</td>\n",
       "      <td>2.5311508921099999</td>\n",
       "      <td>89.786677728300006</td>\n",
       "      <td>41.584766632499999</td>\n",
       "      <td>112.49574782000001</td>\n",
       "      <td>59.0360508196</td>\n",
       "      <td>0.931576460198</td>\n",
       "      <td>0.48992518123000001</td>\n",
       "      <td>0.85516876583599999</td>\n",
       "      <td>0.53369905956100006</td>\n",
       "      <td>0.61669646397099998</td>\n",
       "      <td>0.74007683318700002</td>\n",
       "      <td>0.96569377432000003</td>\n",
       "      <td>0.47261645278199998</td>\n",
       "      <td>75.267156527699996</td>\n",
       "      <td>0.311316176858</td>\n",
       "      <td>0.596118801192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                      1     ...              67         68\n",
       "0          cervix_area                os_area    ...      experts::5  consensus\n",
       "1  0.31789887977100001  0.0089747948552500005    ...             1.0        1.0\n",
       "2  0.55102782467800004  0.0075833088427399997    ...             0.0        1.0\n",
       "3  0.57013533935299998  0.0085532084601100001    ...             0.0        1.0\n",
       "4  0.45640276609300001  0.0069229751559700004    ...             0.0        1.0\n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.read_csv(\"schiller.csv\", header=None)).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 839
    },
    "colab_type": "code",
    "id": "xwPvdXYrRENv",
    "outputId": "426e8875-a91f-492c-91f1-48f560b393aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['cervix_area' 'os_area' 'walls_area' ... 'experts::4' 'experts::5'\n",
      "  'consensus']\n",
      " ['0.34464664392400002' '0.00307978843967' '0.047521707791700001' ...\n",
      "  '1.0' '1.0' '1.0']\n",
      " ['0.16532934808899999' '0.0' '0.048235596648500002' ... '0.0' '0.0'\n",
      "  '0.0']\n",
      " ...\n",
      " ['0.68701706706400001' '0.0086840290583299999' '0.116932365619' ...\n",
      "  '1.0' '0.0' '1.0']\n",
      " ['0.67230050008800002' '0.0034085146597799998' '0.0' ... '0.0' '0.0'\n",
      "  '1.0']\n",
      " ['0.52079518082700005' '0.0060060904749800002' '0.21345284023700001' ...\n",
      "  '1.0' '1.0' '1.0']]\n",
      "(99, 69)\n",
      "\n",
      "\n",
      "[['cervix_area' 'os_area' 'walls_area' ... 'experts::4' 'experts::5'\n",
      "  'consensus']\n",
      " ['0.33465207987599999' '0.0027274720134899998' '0.054514793280200001'\n",
      "  ... '1.0' '1.0' '1.0']\n",
      " ['0.44133214193800002' '0.00239289926394' '0.157184232186' ... '1.0'\n",
      "  '1.0' '1.0']\n",
      " ...\n",
      " ['0.52252103550100004' '0.0054176438894500004' '0.11165124479499999' ...\n",
      "  '1.0' '1.0' '1.0']\n",
      " ['0.627448855473' '0.0059353318619799998' '0.39495494930899999' ...\n",
      "  '1.0' '1.0' '1.0']\n",
      " ['0.57248293101500003' '0.0044135054590000002' '0.38068298268599998' ...\n",
      "  '0.0' '1.0' '1.0']]\n",
      "(98, 69)\n",
      "\n",
      "\n",
      "[['cervix_area' 'os_area' 'walls_area' ... 'experts::4' 'experts::5'\n",
      "  'consensus']\n",
      " ['0.31789887977100001' '0.0089747948552500005' '0.142670408926' ...\n",
      "  '1.0' '1.0' '1.0']\n",
      " ['0.55102782467800004' '0.0075833088427399997' '0.096114110808900005'\n",
      "  ... '0.0' '0.0' '1.0']\n",
      " ...\n",
      " ['0.69661599994599999' '0.0066927875676100002' '0.16908666165299999' ...\n",
      "  '1.0' '0.0' '1.0']\n",
      " ['1.0' '0.0' '0.0' ... '0.0' '0.0' '0.0']\n",
      " ['1.0' '0.0075168720995500002' '0.0' ... '0.0' '0.0' '0.0']]\n",
      "(93, 69)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#np.set_printoptions(threshold=np.inf) #ορίζουμε το threshold ίσο με άπειρο ώστε οι np arrays να εμφανίζονται ολόκληροι \n",
    "                                       #στην οθόνη έτσι ώστε να δούμε αν έχουμε κατηγορικά χαρακτηριστικά\n",
    "np.set_printoptions() #επιστρέφουμε στη default ρύθμιση\n",
    "\n",
    "#εισάγουμε καθένα από τα csv αρχεία και τα μετατρέπουμε σε numpy arrays με τη μέθοδο values\n",
    "green = pd.read_csv(\"green.csv\", header=None).values\n",
    "print(green)\n",
    "print(green.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "hinselmann = pd.read_csv(\"hinselmann.csv\", header=None).values\n",
    "print(hinselmann)\n",
    "print(hinselmann.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "schiller = pd.read_csv(\"schiller.csv\", header=None).values\n",
    "print(schiller)\n",
    "print(schiller.shape)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CsRY42LCA1X8"
   },
   "source": [
    "##Μη διατεταγμένα χαρακτηριστικά, αρίθμηση γραμμών, επικεφαλίδες\n",
    "Με μια πρώτη ματιά παρατηρούμε πως **δεν έχουμε μη διατεταγμένα χαρακτηριστικά**, αφού αυτά είναι όλα αριθμητικά.\n",
    "\n",
    "Βλέπουμε εύκολα πως στις γραμμές δεν έχουμε αρίθμηση, αλλά σε κάθε αρχείο **η πρώτη γραμμή περιέχει τα ονόματα των χαρακτηριστικών και των targets**.\n",
    "Για το λόγο αυτό θα κρατήσουμε την πρώτη γραμμή μόνο από το πρώτο np array (έτσι ώστε να έχουμε διαθέσιμα τα ονόματα των χαρακτηριστικών, αν τα χρειαστούμε) και θα ενώσουμε τα δεδομένα μας σε ένα μεγάλο dataset \"πετώντας\" την πρώτη γραμμή από τα υπόλοιπα δύο."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "6YS7zrZOYuV_",
    "outputId": "ae98a7a4-4e22-4e71-906f-7d29808df3a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 69)\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "arrays = (green[:,:], hinselmann[1:,:], schiller[1:,:])\n",
    "\n",
    "dataset = np.concatenate(arrays)\n",
    "print(dataset.shape) #εδώ έχουμε 288 γραμμές αντί για 287, αφού στην πρώτη βρίσκονται τα feature και target names\n",
    "print(dataset.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N1OFznsAGdn1"
   },
   "source": [
    "##Απουσιάζουσες τιμές\n",
    "Στην περιγραφή του dataset δεν αναφέρεται κάτι για το αν απουσιάζουν τιμές ή όχι, ωστόσο ο παρακάτω έλεγχος μας επιβεβαιώνει ότι τα δεδομένα μας δεν έχουν απουσιάζουσες τιμές."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "o-x1z7G0ijwu",
    "outputId": "a24251f2-2f68-4e9a-ceb1-f633f19dd780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:  0\n"
     ]
    }
   ],
   "source": [
    "#checking for missing values\n",
    "summ=0\n",
    "for val in dataset.all():\n",
    "  if val == np.nan:\n",
    "    summ=summ+1\n",
    "    \n",
    "print(\"Missing Values: \",summ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hyvvzynTbFjS"
   },
   "source": [
    "##Διαχωριμός features, labels\n",
    "Παρακάτω θα διαχωρίσουμε τα features και τα targets σε διαφορετικούς πίνακες. \n",
    "\n",
    "Όπως είπαμε προηγουμένως, τα χαρακτηριστικά βρίσκονται στις **πρώτες 62 στήλες** (άρα dataset[1:, :-7] αφού όλες οι στήλες είναι 69 συνολικά και στην πρώτη γραμμή έχουμε τα ονόματα των χαρακτηριστικών).\n",
    "Ως target θα κρατήσουμε την **τελευταία στήλη** στην οποία βρίσκεται το αποτέλεσμα του consensus, αγνοώντας τις υπόλοιπες (την υποκειμενική γνώμη του κάθε ειδικού). \n",
    "\n",
    "Πιο πάνω είδαμε πως οι τιμές μας έχουν τύπο object, γι' αυτό τις μετατρέπουμε σε **float για τα features** και **integer για τα targets**, έτσι ώστε να είναι συμβατές με τις βιβλιοθήκες της scikit-learn.  Για τον πίνακα labels (που κρατάει το target) εφαρμόζουμε ακόμα τη μέθοδο **flatten()** επειδή θέλουμε αυτός να είναι **μονοδιάστατος**. \n",
    "\n",
    "Στο πίνακα feature_names θα βάλουμε τα ονόματα των χαρακτηριστικών (οι πρώτες 62 στήλες της πρώτης γραμμής.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1089
    },
    "colab_type": "code",
    "id": "byt_X2zclKCO",
    "outputId": "0975b0e7-a959-4b3c-e766-6cca5a4c09d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names:\n",
      "\n",
      "['cervix_area' 'os_area' 'walls_area' 'speculum_area' 'artifacts_area'\n",
      " 'cervix_artifacts_area' 'os_artifacts_area' 'walls_artifacts_area'\n",
      " 'speculum_artifacts_area' 'cervix_specularities_area'\n",
      " 'os_specularities_area' 'walls_specularities_area'\n",
      " 'speculum_specularities_area' 'specularities_area' 'area_h_max_diff'\n",
      " 'rgb_cervix_r_mean' 'rgb_cervix_r_std' 'rgb_cervix_r_mean_minus_std'\n",
      " 'rgb_cervix_r_mean_plus_std' 'rgb_cervix_g_mean' 'rgb_cervix_g_std'\n",
      " 'rgb_cervix_g_mean_minus_std' 'rgb_cervix_g_mean_plus_std'\n",
      " 'rgb_cervix_b_mean' 'rgb_cervix_b_std' 'rgb_cervix_b_mean_minus_std'\n",
      " 'rgb_cervix_b_mean_plus_std' 'rgb_total_r_mean' 'rgb_total_r_std'\n",
      " 'rgb_total_r_mean_minus_std' 'rgb_total_r_mean_plus_std'\n",
      " 'rgb_total_g_mean' 'rgb_total_g_std' 'rgb_total_g_mean_minus_std'\n",
      " 'rgb_total_g_mean_plus_std' 'rgb_total_b_mean' 'rgb_total_b_std'\n",
      " 'rgb_total_b_mean_minus_std' 'rgb_total_b_mean_plus_std'\n",
      " 'hsv_cervix_h_mean' 'hsv_cervix_h_std' 'hsv_cervix_s_mean'\n",
      " 'hsv_cervix_s_std' 'hsv_cervix_v_mean' 'hsv_cervix_v_std'\n",
      " 'hsv_total_h_mean' 'hsv_total_h_std' 'hsv_total_s_mean' 'hsv_total_s_std'\n",
      " 'hsv_total_v_mean' 'hsv_total_v_std' 'fit_cervix_hull_rate'\n",
      " 'fit_cervix_hull_total' 'fit_cervix_bbox_rate' 'fit_cervix_bbox_total'\n",
      " 'fit_circle_rate' 'fit_circle_total' 'fit_ellipse_rate'\n",
      " 'fit_ellipse_total' 'fit_ellipse_goodness' 'dist_to_center_cervix'\n",
      " 'dist_to_center_os']\n",
      "\n",
      "\n",
      "Features:\n",
      "\n",
      "[[3.44646644e-01 3.07978844e-03 4.75217078e-02 ... 8.54743113e+01\n",
      "  2.65933125e-01 3.46293521e-01]\n",
      " [1.65329348e-01 0.00000000e+00 4.82355966e-02 ... 1.24794129e+02\n",
      "  1.00000000e+00 2.83059065e-01]\n",
      " [4.57010481e-01 1.68118335e-03 2.42887859e-01 ... 9.49486971e+01\n",
      "  5.18739791e-01 4.19375125e-01]\n",
      " ...\n",
      " [6.96616000e-01 6.69278757e-03 1.69086662e-01 ... 1.96767870e+02\n",
      "  4.53208712e-01 5.90185377e-01]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 ... 3.56792378e+02\n",
      "  1.00000000e+00 4.02562574e-01]\n",
      " [1.00000000e+00 7.51687210e-03 0.00000000e+00 ... 3.56792378e+02\n",
      "  2.20803705e-01 4.02562574e-01]]\n",
      "(287, 62)\n",
      "\n",
      "\n",
      "Labels:\n",
      "\n",
      "[1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 0 0 0 1 1 1 1 1\n",
      " 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 1 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1\n",
      " 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 0 0]\n",
      "(287,)\n",
      "\n",
      "\n",
      "Label names:\n",
      "\n",
      "['Bad', 'Good']\n"
     ]
    }
   ],
   "source": [
    "#defining features, targets, feature_names\n",
    "\n",
    "feature_names = dataset[0, :-7]\n",
    "print('Feature names:\\n')\n",
    "print(feature_names)\n",
    "print('\\n')\n",
    "\n",
    "features = dataset[1:, :-7].astype(float)\n",
    "print('Features:\\n')\n",
    "print(features)\n",
    "print(features.shape)\n",
    "print('\\n')\n",
    "\n",
    "labels = dataset[1:, -1:].astype(float).astype(int).flatten()\n",
    "print('Labels:\\n')\n",
    "print(labels)\n",
    "print(labels.shape)\n",
    "print('\\n')\n",
    "\n",
    "label_names = ['Bad','Good']\n",
    "print('Label names:\\n')\n",
    "print(label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p-R0IdbKi4T1"
   },
   "source": [
    "##Ισορροπία, διαχωρισμός σε train, test\n",
    "Όπως ήδη γνωρίζουμε ο αριθμός των κλάσεων είναι 2: 0 και 1 (bad και good αντίστοιχα). Παρατηρούμε παρακάτω πως αυτές **δεν** είναι ισορροπημένες αφού συναντάμε το 0 με συχνότητα 71/287=0.25 ή 25% και το 1 με συχνότητα 216/287=0.75 ή 75%.\n",
    "\n",
    "<br>\n",
    "\n",
    "Χωρίζουμε τα data σε train και test, με το test να αποτελεί το 20% του συνόλου δεδομένων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vF3LNwKVjHaC",
    "outputId": "924ba3af-c458-45ee-d4ab-a7a1a6fa78ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequencies: [ 71 216]\n"
     ]
    }
   ],
   "source": [
    "print(\"frequencies:\", np.bincount(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zTN9P3jgnj3v",
    "outputId": "1927ca38-7f2b-44ea-c942-d3f7d79c8f20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58, 62)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test, train_labels, test_labels = train_test_split(features, labels, test_size=0.20)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VTzfcmKkl5wW"
   },
   "source": [
    "#Γ. Baseline classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FIC4J2uMm5gK"
   },
   "source": [
    "##Απλή αρχικοποίηση ταξινομητών\n",
    "Παρακάτω θα εκπαιδεύσουμε τους Dummy Classifiers (για όλες τις στρατηγικές που έχουμε διδαχτεί στο εργαστήριο) καθώς και τον KNeighbors Classifier με τις default τιμές του. Δε θα κάνουμε ακόμα καμία προεπεξεργασία στα δεδομένα μας. Για τον καθένα θα εκτυπώσουμε το classification report (όπου φαίνονται οι μετρικές f1 marco average και f1 micro average) και τον πίνακα σύγχυσης. Τέλος, θα  κρατήσουμε την κάθε averaged μετρική σε ένα dictionary για όλα τα μοντέλα, έτσι ώστε να μπορέσουμε να τις απεικονίσουμε με διαγράμματα και να συγκρίνουμε τις επιδόσεις των μοντέλων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yc1y2Hkh9ROD"
   },
   "outputs": [],
   "source": [
    "#Insert useful modules\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ftwOKfp8B-PL"
   },
   "source": [
    "##Dummy Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1180
    },
    "colab_type": "code",
    "id": "6SpMhxFCtISg",
    "outputId": "0a8e20af-664c-4a34-abc2-7c8ba0f84d0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Uniform: \n",
      "[[ 7 11]\n",
      " [22 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.39      0.30        18\n",
      "           1       0.62      0.45      0.52        40\n",
      "\n",
      "   micro avg       0.43      0.43      0.43        58\n",
      "   macro avg       0.43      0.42      0.41        58\n",
      "weighted avg       0.50      0.43      0.45        58\n",
      "\n",
      "Dummy Constant 0: \n",
      "[[18  0]\n",
      " [40  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      1.00      0.47        18\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "   micro avg       0.31      0.31      0.31        58\n",
      "   macro avg       0.16      0.50      0.24        58\n",
      "weighted avg       0.10      0.31      0.15        58\n",
      "\n",
      "Dummy Constant 1: \n",
      "[[ 0 18]\n",
      " [ 0 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.69      1.00      0.82        40\n",
      "\n",
      "   micro avg       0.69      0.69      0.69        58\n",
      "   macro avg       0.34      0.50      0.41        58\n",
      "weighted avg       0.48      0.69      0.56        58\n",
      "\n",
      "Dummy Most Frequent: \n",
      "[[ 0 18]\n",
      " [ 0 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.69      1.00      0.82        40\n",
      "\n",
      "   micro avg       0.69      0.69      0.69        58\n",
      "   macro avg       0.34      0.50      0.41        58\n",
      "weighted avg       0.48      0.69      0.56        58\n",
      "\n",
      "Dummy Stratified: \n",
      "[[ 7 11]\n",
      " [ 7 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.39      0.44        18\n",
      "           1       0.75      0.82      0.79        40\n",
      "\n",
      "   micro avg       0.69      0.69      0.69        58\n",
      "   macro avg       0.62      0.61      0.61        58\n",
      "weighted avg       0.67      0.69      0.68        58\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Define Models\n",
    "uniform=DummyClassifier(strategy=\"uniform\")\n",
    "constant_0=DummyClassifier(strategy=\"constant\", constant=0)\n",
    "constant_1=DummyClassifier(strategy=\"constant\", constant=1)\n",
    "most_frequent=DummyClassifier(strategy=\"most_frequent\")\n",
    "stratified=DummyClassifier(strategy=\"stratified\")\n",
    "\n",
    "#Train Models\n",
    "model = uniform.fit(train, train_labels)\n",
    "model = constant_0.fit(train, train_labels)\n",
    "model = constant_1.fit(train, train_labels)\n",
    "model = most_frequent.fit(train, train_labels)\n",
    "model = stratified.fit(train, train_labels)\n",
    "\n",
    "#f1_micro and f1_macro will hold the respective metrics of each Classifier\n",
    "f1_micro = {}\n",
    "f1_macro = {}\n",
    "\n",
    "\n",
    "#Test Models and print Confusion Matrix and Classification Report\n",
    "\n",
    "#Uniform\n",
    "preds = uniform.predict(test)\n",
    "matrix = confusion_matrix(test_labels, preds)\n",
    "clas_rep = classification_report(test_labels, preds)\n",
    "print('Dummy Uniform: ')\n",
    "print(matrix)\n",
    "print(clas_rep)\n",
    "f1_micro['uniform'] = f1_score(test_labels, preds, average = 'micro')\n",
    "f1_macro['uniform'] = f1_score(test_labels, preds, average = 'macro')\n",
    "\n",
    "#Constant 0\n",
    "preds = constant_0.predict(test)\n",
    "matrix = confusion_matrix(test_labels, preds)\n",
    "clas_rep = classification_report(test_labels, preds)\n",
    "print('Dummy Constant 0: ')\n",
    "print(matrix)\n",
    "print(clas_rep)\n",
    "f1_micro['constant_0'] = f1_score(test_labels, preds, average = 'micro')\n",
    "f1_macro['constant_0'] = f1_score(test_labels, preds, average = 'macro')\n",
    "\n",
    "#Constant 1\n",
    "preds = constant_1.predict(test)\n",
    "matrix = confusion_matrix(test_labels, preds)\n",
    "clas_rep = classification_report(test_labels, preds)\n",
    "print('Dummy Constant 1: ')\n",
    "print(matrix)\n",
    "print(clas_rep)\n",
    "f1_micro['constant_1'] = f1_score(test_labels, preds, average = 'micro')\n",
    "f1_macro['constant_1'] = f1_score(test_labels, preds, average = 'macro')\n",
    "\n",
    "#Most Frequent\n",
    "preds = most_frequent.predict(test)\n",
    "matrix = confusion_matrix(test_labels, preds)\n",
    "clas_rep = classification_report(test_labels, preds)\n",
    "print('Dummy Most Frequent: ')\n",
    "print(matrix)\n",
    "print(clas_rep)\n",
    "f1_micro['most_frequent'] = f1_score(test_labels, preds, average = 'micro')\n",
    "f1_macro['most_frequent'] = f1_score(test_labels, preds, average = 'macro')\n",
    "\n",
    "#Stratified\n",
    "preds = stratified.predict(test)\n",
    "matrix = confusion_matrix(test_labels, preds)\n",
    "clas_rep = classification_report(test_labels, preds)\n",
    "print('Dummy Stratified: ')\n",
    "print(matrix)\n",
    "print(clas_rep)\n",
    "f1_micro['stratified'] = f1_score(test_labels, preds, average = 'micro')\n",
    "f1_macro['stratified'] = f1_score(test_labels, preds, average = 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pvzGnElECDRa"
   },
   "source": [
    "##KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "id": "iPRng7a1AgX-",
    "outputId": "5740684d-d55a-4c78-d249-dec4f98f9b7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kneighbors Default: \n",
      "[[ 4 14]\n",
      " [ 2 38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.22      0.33        18\n",
      "           1       0.73      0.95      0.83        40\n",
      "\n",
      "   micro avg       0.72      0.72      0.72        58\n",
      "   macro avg       0.70      0.59      0.58        58\n",
      "weighted avg       0.71      0.72      0.67        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#KNeighbors Classifier with default values\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Define Model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#Train Model\n",
    "model = knn.fit(train, train_labels)\n",
    "\n",
    "#Test Model and print Confusion Matrix and Classification Report\n",
    "preds = knn.predict(test)\n",
    "matrix = confusion_matrix(test_labels, preds)\n",
    "clas_rep = classification_report(test_labels, preds)\n",
    "print('Kneighbors Default: ')\n",
    "print(matrix)\n",
    "print(clas_rep)\n",
    "f1_micro['knn_default'] = f1_score(test_labels, preds, average = 'micro')\n",
    "f1_macro['knn_default'] = f1_score(test_labels, preds, average = 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7nIeI3M8CsjG"
   },
   "source": [
    "##Plots, Σχολιασμός"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GCtWN4VDGQCF"
   },
   "source": [
    "###f1_micro average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "TVIF4Km8GE47",
    "outputId": "29c178ea-c4dc-4d3b-b87f-549332cc9067"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XtcVHX+x/H3wGheoAKd0cwuZhaG\naeGlDLUySLft6g1KkNLy4T40zbKHLmX0c4XV8paXzVIz10tSSppai6XWlothaaj0UNGM8JIMiuho\nK6jn90ePZiUHB5Phi/B6/uOcOefM+fAZzrzP+Z7xYLMsyxIAAKh0AaYLAACgpiKEAQAwhBAGAMAQ\nQhgAAEMIYQAADCGEAQAwxF7ZG3S5jlX2JitUSEg9FRaeMF1GlUNfvKMv3tEX7+iLd9WhLw5HsNfn\nORO+QHZ7oOkSqiT64h198Y6+eEdfvKvOfSGEAQAwhBAGAMAQQhgAAEMIYQAADCGEAQAwhBAGAMAQ\nQhgAAEMIYQAADCGEAQAwhBAGAMAQQhgAAEMIYQAADKn0v6IEALi09R+31nQJfvXOqK6Vti3OhAEA\nMIQQBgDAEEIYAABDCGEAAAwhhAEAMKRc345OSUlRVlaWbDabEhMT1bp1a0nSwYMHNWLECM9yeXl5\neuGFF/TQQw/5p1oAAKoRnyGcmZmp3Nxcpaamavfu3UpMTFRqaqokqVGjRpo/f74k6dSpU4qPj1fX\nrpX31W4AAC5lPoejMzIyFBUVJUlq3ry5ioqK5Ha7z1nuww8/VLdu3VS/fv2KrxIAgGrIZwgXFBQo\nJCTEMx0aGiqXy3XOch988IF69epVsdUBAFCNXfAdsyzLOue5zZs364YbblBQUJDP9UNC6sluD7zQ\nzVYpDkew6RKqJPriHX3xjr54R1/Mq8z3wGcIO51OFRQUeKbz8/PlcDhKLfP555+rY8eO5dpgYeGJ\nCyyxanE4guVyHTNdRpVDX7yjL97RF+/oS9Xgj/egrGD3ORwdGRmp9PR0SVJ2dracTuc5Z7xbt25V\nWFhYBZQJAEDN4fNMOCIiQuHh4YqNjZXNZlNSUpLS0tIUHBys6OhoSZLL5VKDBg38XiwAANVJua4J\nn/1/gSWdc9a7YsWKiqsI8CP++ot39MU7+gJ/445ZAAAYQggDAGAIIQwAgCGEMAAAhhDCAAAYQggD\nAGAIIQwAgCGEMAAAhhDCAAAYQggDAGAIIQwAgCGEMAAAhhDCAAAYQggDAGAIIQwAgCGEMAAAhhDC\nAAAYQggDAGAIIQwAgCGEMAAAhhDCAAAYQggDAGAIIQwAgCGEMAAAhhDCAAAYQggDAGAIIQwAgCGE\nMAAAhhDCAAAYQggDAGCIvTwLpaSkKCsrSzabTYmJiWrdurVn3oEDB/T888+rpKREt9xyi8aMGeO3\nYgEAqE58nglnZmYqNzdXqampSk5OVnJycqn548aNU//+/bVkyRIFBgZq//79fisWAIDqxGcIZ2Rk\nKCoqSpLUvHlzFRUVye12S5LOnDmjb7/9Vl27dpUkJSUlqUmTJn4sFwCA6sNnCBcUFCgkJMQzHRoa\nKpfLJUk6fPiw6tevr7///e96/PHHNXHiRP9VCgBANVOua8Jnsyyr1OODBw+qX79+uvrqqzVw4EB9\n/vnnuueee8pcPySknuz2wD9UbFXhcASbLqFKoi/m8R54R1+8oy/eVWZffIaw0+lUQUGBZzo/P18O\nh0OSFBISoiZNmujaa6+VJHXs2FE5OTnnDeHCwhMXWbJZDkewXK5jpsuocuhL1cB74B198Y6+eOeP\nvpQV7D6HoyMjI5Weni5Jys7OltPpVFBQkCTJbrfrmmuu0Y8//uiZ36xZswoqGQCA6s3nmXBERITC\nw8MVGxsrm82mpKQkpaWlKTg4WNHR0UpMTNSoUaNkWZZuuukmz5e0AADA+ZXrmvCIESNKTYeFhXke\nX3fddXrvvfcqtioAAGoA7pgFAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBg\nCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAA\nGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAA\nAIYQwgAAGGIvz0IpKSnKysqSzWZTYmKiWrdu7ZnXtWtXNW7cWIGBgZKkCRMmqFGjRv6pFgCAasRn\nCGdmZio3N1epqanavXu3EhMTlZqaWmqZWbNmqX79+n4rEgCA6sjncHRGRoaioqIkSc2bN1dRUZHc\nbrffCwMAoLrzeSZcUFCg8PBwz3RoaKhcLpeCgoI8zyUlJWnfvn1q27atXnjhBdlstjJfLySknuz2\nwIss2yyHI9h0CVUSfTGP98A7+uIdffGuMvtSrmvCZ7Msq9T00KFD1blzZ11xxRUaPHiw0tPT1b17\n9zLXLyw8ceFVViEOR7BcrmOmy6hy6EvVwHvgHX3xjr5454++lBXsPoejnU6nCgoKPNP5+flyOBye\n6UcffVQNGjSQ3W5Xly5dtHPnzgooFwCA6s9nCEdGRio9PV2SlJ2dLafT6RmKPnbsmAYMGKDi4mJJ\n0saNG9WiRQs/lgsAQPXhczg6IiJC4eHhio2Nlc1mU1JSktLS0hQcHKzo6Gh16dJFMTExuuyyy3TL\nLbecdygaAAD8T7muCY8YMaLUdFhYmOdxQkKCEhISKrYqAABqAO6YBQCAIYQwAACGEMIAABhCCAMA\nYAghDACAIYQwAACGEMIAABhCCAMAYAghDACAIYQwAACGEMIAABhCCAMAYAghDACAIYQwAACGEMIA\nABhCCAMAYAghDACAIYQwAACGEMIAABhCCAMAYAghDACAIXbTBVys/uPWmi7Br94Z1dV0CQAAP+FM\nGAAAQwhhAAAMIYQBADCEEAYAwBBCGAAAQwhhAAAMIYQBADCEEAYAwJByhXBKSopiYmIUGxurLVu2\neF1m4sSJio+Pr9DiAACoznyGcGZmpnJzc5Wamqrk5GQlJyefs8yuXbu0ceNGvxQIAEB15TOEMzIy\nFBUVJUlq3ry5ioqK5Ha7Sy0zbtw4DR8+3D8VAgBQTfkM4YKCAoWEhHimQ0ND5XK5PNNpaWnq0KGD\nrr76av9UCABANXXBf8DBsizP4yNHjigtLU1z587VwYMHy7V+SEg92e2BF7rZGsvhCDZdQrldSrVW\nV7wH3tEX7+iLd5XZF58h7HQ6VVBQ4JnOz8+Xw+GQJG3YsEGHDx9W3759VVxcrJ9++kkpKSlKTEws\n8/UKC09UQNk1h8t1zHQJ5eJwBF8ytVZnvAfe0Rfv6It3/uhLWcHuczg6MjJS6enpkqTs7Gw5nU4F\nBQVJkrp3766PP/5Y77//vqZPn67w8PDzBjAAAPgfn2fCERERCg8PV2xsrGw2m5KSkpSWlqbg4GBF\nR0dXRo0AAFRL5bomPGLEiFLTYWFh5yzTtGlTzZ8/v2KqAgCgBuCOWQAAGEIIAwBgCCEMAIAhhDAA\nAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEM\nAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEII\nAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgiL08C6WkpCgrK0s2m02JiYlq3bq1Z97777+vJUuWKCAg\nQGFhYUpKSpLNZvNbwSif/uPWmi7Br94Z1dV0CQBw0XyeCWdmZio3N1epqalKTk5WcnKyZ94vv/yi\nVatWaeHChVq8eLF++OEHbd682a8FAwBQXfgM4YyMDEVFRUmSmjdvrqKiIrndbklS3bp1NW/ePNWq\nVUu//PKL3G63HA6HfysGAKCa8BnCBQUFCgkJ8UyHhobK5XKVWubtt99WdHS0unfvrmuuuabiqwQA\noBoq1zXhs1mWdc5zAwcOVL9+/fTMM8+obdu2atu2bZnrh4TUk90eeKGbrbEcjmDTJVRJ9MU7+uId\nffGOvnhXmX3xGcJOp1MFBQWe6fz8fM+Q85EjR5STk6P27durTp066tKlizZt2nTeEC4sPFEBZdcc\nLtcx0yVUSfTFO/riHX3xjr5454++lBXsPoejIyMjlZ6eLknKzs6W0+lUUFCQJOnUqVMaNWqUjh8/\nLknaunWrmjVrVlE1AwBQrfk8E46IiFB4eLhiY2Nls9mUlJSktLQ0BQcHKzo6WoMHD1a/fv1kt9t1\n880367777quMugEAuOSV65rwiBEjSk2HhYV5Hvfo0UM9evSo2KoAAKgBuGMWAACGEMIAABhCCAMA\nYAghDACAIYQwAACGEMIAABhCCAMAYAghDACAIYQwAACGEMIAABhCCAMAYAghDACAIYQwAACGEMIA\nABhCCAMAYAghDACAIYQwAACGEMIAABhCCAMAYAghDACAIYQwAACGEMIAABhCCAMAYAghDACAIYQw\nAACGEMIAABhCCAMAYAghDACAIYQwAACGEMIAABhCCAMAYIi9PAulpKQoKytLNptNiYmJat26tWfe\nhg0bNGnSJAUEBKhZs2ZKTk5WQADZDgCALz7TMjMzU7m5uUpNTVVycrKSk5NLzX/llVc0depULV68\nWMePH9eXX37pt2IBAKhOfIZwRkaGoqKiJEnNmzdXUVGR3G63Z35aWpoaN24sSQoNDVVhYaGfSgUA\noHrxORxdUFCg8PBwz3RoaKhcLpeCgoIkyfNvfn6+1q9fr2HDhp339UJC6sluD7yYmmsUhyPYdAlV\nEn3xjr54R1+8oy/eVWZfynVN+GyWZZ3z3KFDhzRo0CAlJSUpJCTkvOsXFp640E3WaC7XMdMlVEn0\nxTv64h198Y6+eOePvpQV7D6Ho51OpwoKCjzT+fn5cjgcnmm3261nnnlGzz33nDp16lQBpQIAUDP4\nDOHIyEilp6dLkrKzs+V0Oj1D0JI0btw4JSQkqEuXLv6rEgCAasjncHRERITCw8MVGxsrm82mpKQk\npaWlKTg4WJ06ddKyZcuUm5urJUuWSJIefPBBxcTE+L1wAAAudeW6JjxixIhS02FhYZ7H27Ztq9iK\nAACoIbirBgAAhhDCAAAYQggDAGAIIQwAgCGEMAAAhhDCAAAYQggDAGAIIQwAgCGEMAAAhhDCAAAY\nQggDAGAIIQwAgCGEMAAAhhDCAAAYQggDAGAIIQwAgCGEMAAAhhDCAAAYQggDAGAIIQwAgCGEMAAA\nhhDCAAAYQggDAGAIIQwAgCGEMAAAhhDCAAAYQggDAGAIIQwAgCGEMAAAhhDCAAAYUq4QTklJUUxM\njGJjY7Vly5ZS806ePKmRI0eqR48efikQAIDqymcIZ2ZmKjc3V6mpqUpOTlZycnKp+a+99ppatmzp\ntwIBAKiufIZwRkaGoqKiJEnNmzdXUVGR3G63Z/7w4cM98wEAQPnZfS1QUFCg8PBwz3RoaKhcLpeC\ngoIkSUFBQTpy5Ei5NxgSUk92e+AfKLVmcjiCTZdQJdEX7+iLd/TFO/riXWX2xWcI/55lWRe1wcLC\nExe1fk3jch0zXUKVRF+8oy/e0Rfv6It3/uhLWcHuczja6XSqoKDAM52fny+Hw1FxlQEAUEP5DOHI\nyEilp6dLkrKzs+V0Oj1D0QAA4I/zORwdERGh8PBwxcbGymazKSkpSWlpaQoODlZ0dLSGDh2qn3/+\nWXv27FF8fLz69Omjhx56qDJqBwDgklaua8IjRowoNR0WFuZ5PHXq1IqtCACAGoI7ZgEAYAghDACA\nIYQwAACGEMIAABhCCAMAYAghDACAIYQwAACGEMIAABhCCAMAYAghDACAIYQwAACGEMIAABhCCAMA\nYAghDACAIYQwAACGEMIAABhCCAMAYAghDACAIYQwAACGEMIAABhCCAMAYAghDACAIYQwAACGEMIA\nABhCCAMAYAghDACAIYQwAACGEMIAABhCCAMAYAghDACAIeUK4ZSUFMXExCg2NlZbtmwpNe8///mP\nevXqpZiYGM2YMcMvRQIAUB35DOHMzEzl5uYqNTVVycnJSk5OLjV/7NixmjZtmt577z2tX79eu3bt\n8luxAABUJz5DOCMjQ1FRUZKk5s2bq6ioSG63W5KUl5enK664QldddZUCAgJ09913KyMjw78VAwBQ\nTfgM4YKCAoWEhHimQ0ND5XK5JEkul0uhoaFe5wEAgPOzX+gKlmVd1AYdjuCLWv/3Vkx8pEJfr7qg\nL97RF+/oi3f0xTv6UnF8ngk7nU4VFBR4pvPz8+VwOLzOO3jwoJxOpx/KBACg+vEZwpGRkUpPT5ck\nZWdny+l0KigoSJLUtGlTud1u7d27V6dOndK6desUGRnp34oBAKgmbFY5xpcnTJigb775RjabTUlJ\nSfr+++8VHBys6Ohobdy4URMmTJAk3X///RowYIDfiwYAoDooVwgDAICKxx2zAAAwhBAGAMAQQvg8\n/v3vf2vRokWSpDFjxuixxx7z3KgEwK/2799/zu1sf6+q7D//+te/Km1bv32htTy2b9+uPXv2SJKG\nDx+u//73v9q9e7e6deum+fPnKzk5WXl5eeV6rfHjxystLe0P1YzKRwifR5cuXfTEE09Ikr744gvN\nmzfP881wXNiHzG/cbre++uqr8y5zqd+P3F99OXnypEaOHKkePXr80dL8YsOGDT5DuCrsP8XFxXr3\n3XcrZVt79+7VqlWryr38p59+qh9//FGSNHnyZNWpU0dbt25Vly5dFB8fr5deeknXXHONn6q9OGlp\naRo/frzfXn/BggWaNm1amfPPPli5EPHx8dq5c2e59j1/uuCbdVQHaWlpysnJ0ciRI3X8+HE99NBD\nCgwMVExMjNatW6fi4mLNnTtXq1evVk5Ojho0aKD8/HwNGjRIb731lt58801t2rRJp0+fVt++ffXo\no48qPj5eLVq0kCSFhISosLBQubm52rt3r4YNG6alS5dq3759mjVrVpXdmS7Ebx8y3bp1u6D1srOz\ntX79enXq1KnMZcaOHas5c+aoUaNGiouLU7du3XTjjTdebMmVwp99ee2119SyZUvl5ORcbJmSft0P\nNm7cqMLCQuXk5Gj48OFauXKldu/erQkTJui7777Txx9/LEm67777NHDgQH311VeaMmWK6tSpowYN\nGigpKUnTp0+X3W7XVVddpfvuu++c7cyePduz//Tv318ffPCBTpw4oZEjR2r//v165513ZLfb1apV\nK40aNUput1tDhgzRyZMndeedd2r58uVau3atunbtqhUrVqh+/foaP368WrRooUceeUSjR49WXl6e\nTp06paFDh6pjx46Kj4/XXXfdpQ0bNqiwsFAzZ87UrFmztGPHDr366qt69dVXK6SHv9m/f79efPFF\nBQQE6PTp0woMDFROTo6mT58uy7KUl5envXv36t1339Vf//pXHTx4UCdOnNCzzz6rJk2aaPHixQoN\nDVWDBg303HPPaeHChZo5c6Z++eUXNW3aVJ999plGjx6tJk2aKDExUUVFRTp9+rRefvllhYWFafny\n5Zo9e7YaNWqkOnXqeD6LaoKzD1b+iPLse/5UI0PYm9OnT+uGG27Q008/reHDh2vDhg2eeU8//bQW\nLVqkWbNm6fvvv1dOTo4WL16sEydO6OGHH/bcW7tFixZ6/PHHNW3aNBUVFWnOnDmaPHmyli1bpjlz\n5mjKlClas2aNnnzyyUr/+UpKSjRq1Cjt27dPl112mVJSUjR9+nTl5eWpuLhYQ4cOVadOnRQdHX3O\nwcjRo0dLfcC8/vrrGjNmjLZs2aLp06erV69eevHFFyVJp06d0vjx43XttdcqOjpaUVFR2rRpk4KD\ng/X2229rzJgxcrvduv766xUTE3NOnWffj1yS537k/grhS6Uv0q/DlEeOHNFHH31UYT//jz/+qEWL\nFumDDz7QW2+9pWXLliktLU0zZ87UgQMHtGTJEklS79691b17dy1YsECjRo1Su3bttHr1ap0+fVqP\nPfaYQkJCvAawVHr/2bZtm3bu3Kn09HSVlJRo9OjRSk1NVe3atTVs2DB9++232r59u1q2bKmRI0f6\nPJtcsWKFHA6HUlJSdPjwYSUkJGjFihWSpKCgIM2bN08TJkzQ6tWrNWDAAGVlZVV4AEu/jn7cdddd\nGjx4sOdDPSQkREOGDNG0adNUUlKiRYsW6dChQ+rUqZMee+wx5eXladiwYUpLS1Pnzp3VrVs3tW7d\nWpJ0+eWXa+DAgcrJyVFCQoI+++wzSdK8efPUuXNn9e7dW7t27VJycrLeeecdTZ48WUuXLtXll19u\ndKRk4sSJqlu3rvbt26fDhw9rz549GjBggHr37u11HyprZCQjI0MpKSlq2LChHA6H58Rl8uTJ+uab\nb3T69GnFxcXprrvuKnWw0qJFC73xxhuqVauWLr/8ck2ZMkWbN2/WwoULNXXqVEnSHXfcoa+//tqz\nrfLse/7EcPRZ2rVrJ0lq3Lixjh075nWZbdu2qX379pKkevXq6cYbb1Rubq4keXYgSbr11lslSQ6H\nQy1btpQkNWzY0Ng1sWXLlqlhw4ZavHix+vTpow8//FC1a9f2DPX87W9/k/S/g5GFCxeqadOm2rBh\ng+cDZv78+XrppZfkcrk0YMAAdejQQUOGDFF+fr4GDx6s+fPnq2fPnp7r6Hl5eXrkkUeUmpqqo0eP\naseOHRowYIAeeOCBMn/ZK/t+5JdKXyT5ZSi3VatWstlscjgcuvnmmxUYGKiGDRtqx44datOmjex2\nu+x2uyIiIrR9+3Z1795dSUlJmjlzplq2bOm5e96FuPnmm1W7dm3t2rVL+/fv14ABAxQfH6/c3Fzt\n379fu3fvVps2bSRJHTp0OO9rbd68WWvWrFF8fLyGDRumkydPqri4WFLp/dnf+11kZKSWL1+ucePG\nqbi42FP/b84O161btyo2NlYjR47UkSNHLmg7mzdv1nvvvaf4+Hj93//9n44dO6bCwkLVr19fDRo0\nUK1atRQREVFhP9eF+OSTT3TgwAE1btxYO3fu1PTp0zVjxgwtWLBAkvd9qCwTJ07U66+/rrlz56qw\nsFCS9M0332jfvn1auHCh/vnPf+rNN99UvXr1NHDgQD3wwANKSEhQUVGRJkyYoAULFigoKKhcw8zl\n2ff8qUaeCdtsNs/jU6dOeR4HBgZ6Hpf136fPXlf69UwqIODXY5latWp5nrfb7V4fm/pv2dnZ2erY\nsaMk6c9//rPGjh2rO+64Q5LUqFEj1a5d2/OB8PuDkcjISA0ZMkTHjh1Tt27ddPvtt5c6knQ4HJ4/\naXn06FGFh4dL+jU0wsLCSr1WVVPT+1LW72lRUVGp39Xffs8fffRRde7cWZ999pn+8pe/6I033rjg\nbdauXVvSr/tLq1atNGfOnFLzN23a5NnPzt4nz1ZSUuJ5jUGDBunBBx88Z5ny7M8V5aabbtLy5cu1\nfv16TZo0ST179iw1/7fPhpUrV6qoqEiLFi3SkSNH1KtXrwvaTq1atTR69GjdfvvtnucOHz7s+QyS\nzHzG5OTkaPXq1fr444+1atUq3XbbbQoMDDzn97s8JzqStG/fPs8+0r59e508eVKbNm1SVlaWZ9j5\nzJkz5xygh4aG6uWXX9bp06eVl5enO++8U/Xr16/oH7dC1cgz4aCgIOXn50uSvv322wtat1WrVp4P\n2uPHj+unn37SddddV+E1VrTAwECdOXOm1HNn76zFxcWeHfn3H16/fcC0a9dOkyZN0rJly0q9ztSp\nU9WpUyctXLhQgwcPLrXNsrZXlsq+H/ml0pfKFh0dre+++06nTp3SqVOnlJWVpZYtW2rGjBmy2+2K\niYnRAw88oN27d8tms5U6mC2vZs2aaffu3Tp06JCkX/t18OBB3XDDDcrKypKkUn8aNSgoSC6XS6dP\nn/bMb9OmjdasWSNJOnTokCZNmlTm9n67bOAPq1atUk5OjqKiojxDzN56UlhYqKZNmyogIECffvqp\n56zdZrOVq7Y2bdp4hqZ37dqluXPn6sorr9SxY8d09OhRlZSUaNOmTRX7w5XDvn371KJFC8+3z88+\noDtbeQ+MvB1U1K5dW7169dL8+fM1f/58ffLJJ+d8vyYxMVGvvPKKFixY4Lk88vsTpz/yu+pPNTKE\nO3bsqD179ig+Pl4//PDDOW/S+bRr106tWrVS37591b9/f73wwguqV6+eH6utGLfeeqtn+GfdunW6\n8sorPQcTBw4cUEBAgC6//HKv6/7+A2bbtm0KCAjw/DIXFhbq2muvlWVZWrNmjecsxZuz1/Omsu9H\nfqn0xYSYmBjFxcWpb9++6t27t66++mo1adJETz31lJ588klt375dnTt31u23367Zs2df8LXqunXr\nKjExUc8884xiY2N15MgROZ1OPfLII9q6dav69u2rHTt2eJaPi4vToEGDNGTIEM93BP70pz+pXr16\nio2N1aBBg9S2bdsyt+dwOFRSUqKhQ4f+sYacx/XXX68xY8aoX79+mjFjhoYOHarvv/9eKSkppZa7\n//77tXbtWiUkJKhu3bpq3Lixpk+frnbt2mns2LE+/x57XFycfvrpJz3xxBN6+eWX1a5dOwUEBGjI\nkCGKi4vT0KFDjXwp65577lFKSor+8Y9/lDqI/qMaNWqkH374QZZlKTMzU9KvQ/rr1q3TmTNndPLk\nSc+lorO53W5dddVVOnr0qL7++muVlJSUOunavn27jh8/Xmod4/uehRrh5MmT1osvvmj17dvXSkhI\nsPbu3WslJiZacXFxVkxMjJWZmWlZlmXde++9ltvttizLssaNG2ctXbrU2rZtm9WzZ08rPj7eevLJ\nJ61du3ZZhw4dsu6++24rOTnZWrt2rdWtWzerf//+1rp166xOnTpZX375pdWhQwfP9p999llrw4YN\n1o4dO6zIyEhr9uzZZdaamZlp9enTx+rTp895l6tpfXn22Wet3r17W7fddpsVFxdnffTRR37tTVXg\ndrute++913QZOI+lS5da48aNsyzLslauXGm1b9/eM332++dtHyrLF198YT344IPWwIEDrcTERGvq\n1KmWZVnWpEmTrF69elk9e/ZNGaNAAAAAtUlEQVT0rH/29qdMmWI9/PDD1tChQ620tDTr3nvvtX7+\n+WfrqaeesmJiYqxx48ZZXbt2tSzLsuLi4qwdO3aUa9/zJ+4dDaBCpKamauXKlec8//zzz5e6hnkh\nfvsvhGvXrr3Y8oAqiRCGEWvWrPF644R+/fopOjq68guqIugLaor9+/dr5MiR5zzfvn17v1wyqKoI\nYQAADKmRX8wCAKAqIIQBADCEEAYAwBBCGAAAQwhhAAAM+X+TCltSqghvkgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6afd4ad3c8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(range(len(f1_micro)), list(f1_micro.values()), align='center')\n",
    "plt.xticks(range(len(f1_micro)), list(f1_micro.keys()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2b0KBRWUIko8"
   },
   "source": [
    "###f1_macro average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "x827OmuAIoB-",
    "outputId": "a4f73ff4-6991-48f4-9500-ac46d4fd1134"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6afd4ad198>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(len(f1_macro)), list(f1_macro.values()), align='center')\n",
    "plt.xticks(range(len(f1_macro)), list(f1_macro.keys()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YRyYE42lJskx"
   },
   "source": [
    "###Σχολιασμός\n",
    "- Precision είναι ο λόγος των true positives (Tp) ως προς τον αριθμό των true positives συν τον αριθμό των false positives (Fp). \n",
    "- Recall είναι ο λόγος των true positives (Tp) ως προς τον αριθμό των true positives συν τον αριθμό των false negatives (Fn).\n",
    "\n",
    "Γενικά όταν το Recall έχει υψηλή τιμή το μοντέλο μας προβλέπει καλά τη θετική κλάση (1) (όπως στον Dummy Constant 1) ενώ το Precision ίσως να μην έχει τόσο υψηλή τιμή. Ιδανικά θέλουμε υψηλό precision και υψηλό recall, αλλά μεταξύ των 2 υπάρχει συνήθως trade off. \n",
    "\n",
    "Βέβαια, για το συγκεκριμένο dataset θα θέλαμε να προβλέπουν τα μοντέλα μας πιο καλά το 0, δηλαδή τις κακές κολποσκοπήσεις (δε μας πειράζει να έχουμε και κάποια false negatives αρκεί να έχουμε όσο πιο λίγο false posotives). Κοιτώντας τους πίνακες σύγχυσης βλέπουμε πως τ κοντινότερο μοντέλο σε αυτό που ζητάμε θα ήταν το Dummy Constant 0 (λογικό, αφού αυτό προβλέπει συνέχεια την κλάση 0, άρα δε γίνεται να έχουμε false positives).\n",
    "\n",
    "- Το F1 score είναι ο αρμονικός μέσος της ακρίβειας και της ανάκλησης. Στην πράξη χρησιμοποιείται περισσότερο από τα άλλα δύο, καθώς επιτρέπει στα μοντέλα μας να έχουν τόσο καλό precision όσο και καλό recall. \n",
    "- Το F1 macro average παίρνει απλά το μέσο όρο των precision, recall\n",
    "- To F1 micro average υπολογίζει ξεχωριστά τη συμβολή που έχει η κάθε κλάση στο σύνολο και με βάση αυτή θα βγάλει το μέσο.\n",
    "- Από τα παραπάνω διαγράμματα παρατηρούμε ότι ο Constant 1 (και αντίστοιχα ο Most Frequent) δίνει το καλύτερο F1 micro average (λογικό, αφού τα περισσότερα δείγματά μας είναι θετικά και αυτό προβλέπει συνέχεια το 1) ενώ το καλύτερο F1 macro average δίνει ο KNeighbors Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x-cpXmXkYr4G"
   },
   "source": [
    "#Δ. Βελτιστοποίηση ταξινομητών"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7SxMTZ3M8vPz"
   },
   "source": [
    "Για τον KNeighbors Classifier θα προσπαθήσουμε να βρούμε τη βέλτιστη αρχιτεκτονική. Για το λόγο αυτό θα χρειαστεί να κάνουμε την κατάλληλη προεπεξεργασία στα δεδομένα μας.\n",
    "\n",
    "Αρχικά θα κάνουμε επιλογή χαρακτηριστικών στο train set με βάση τη διακύμανση των τιμών τους. Στη συνέχεια θα κανονικοποιήσουμε και θα εξισορροπήσουμε τα δεδομένα έτσι ώστε να έχουμε ίσο αριθμό δειγμάτων για κάθε κλάση. Το επόμενο βήμα είναι να κάνουμε εξαγωγή νέων χαρακτηριστικών με ανάλυση σε κύριες συνιστώσες. Τέλος θα δοκιμάσουμε τον ταξινομητή μας για τα διάφορα k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RiVdW0Zze0Wo"
   },
   "source": [
    "##Variance Threshold\n",
    "\n",
    "Αρχικά θα κοιτάξουμε να βρούμε τη μέγιστη και ελάχιστη απόκλιση των χαρακτηριστικών του train set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "jdDU3qiXim-0",
    "outputId": "b40991a7-578a-4a36-8483-efddff3c3a00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max variance is  8002.180994195962\n",
      "Min variance is  3.728774474362219e-05\n",
      "Max scaled variance is  0.08664143169172439\n",
      "Min scaled variance is  0.007329603548654596\n"
     ]
    }
   ],
   "source": [
    "variance = np.var(train, axis=0)\n",
    "\n",
    "maxx = max(variance)\n",
    "print(\"Max variance is \", maxx)\n",
    "\n",
    "minn  = min(variance)\n",
    "print(\"Min variance is \", minn)\n",
    "\n",
    "threshold = [0, 2, 20, 200, 2000] #προσαρμόζουμε τις τιμές του thresold στο variance που παρατηρήσαμε\n",
    "\n",
    "#Τα παρπακάτω μας χρειάζονται για να προσδιορίσουμε το threshold του selector στην περίπτωση που χρησιμοποιήσουμε min-max scaler για το grid search\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train)\n",
    "variance = np.var(train_scaled, axis=0)\n",
    "\n",
    "maxx = max(variance)\n",
    "print(\"Max scaled variance is \", maxx)\n",
    "\n",
    "minn  = min(variance)\n",
    "print(\"Min scaled variance is \", minn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R-Z2tFNPkYu-"
   },
   "source": [
    "##Grid Search\n",
    "Αφού βρήκαμε το variance είμαστε έτοιμοι να κάνουμε το grid search.\n",
    "\n",
    "Θα χρησιμοποιήσουμε την KFold για να διαχωρίσουμε το train set σε 10 folds για να κάνουμε cross validation. Στο cross validation, για κάθε στάδιο προεπεξεργασίας αλλά και στο στάδιο ταξινόμησης, κάνουμε fit και transform στα folds που προορίζονται για train και απλά transform (ή αντίστοιχα predict για τον ταξινομητή) στο fold που προορίζεται για test.\n",
    "\n",
    "Θα ξεκινήσουμε με τον VarianceThreshold και σε κάθε βήμα θα προσθέτουμε ένα ακόμα στάδιο προεπεξεργασίας (με τη σειρά που αναφέρθηκαν παραπάνω) μέχρι να βρούμε τη βέλτιστη αρχιτεκτονική. Εξαίρεση αποτελεί ο Min-max scaler για τον οποίο πρέπει να κάνουμε κανονικοποίηση πρωτού κάνουμε επιλογή δεδομένων με τον VarianceThreshold.\n",
    "\n",
    "Για ευκολία, θα παρουσιάσουμε τον κώδικα μία φορά για όλα τα στάδια προεπεξεργασίας και τα αποτελέσματα για το κάθε βήμα θα παρουσιαστούν ξεχωριστά σε Markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ZaOC3vhYuhI"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler # φέρνουμε τον StandarScaler ως transformer που έχει transform() kai όχι ως scale()\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from statistics import mean\n",
    "\n",
    "neighbors = [1, 5, 11, 21, 31, 41, 51]\n",
    "n_components = [3, 5, 7, 10, 12]\n",
    "\n",
    "thr=0\n",
    "ncomp=0\n",
    "k=0\n",
    "sc=0\n",
    "kf=KFold(n_splits=10)\n",
    "\n",
    "for n in neighbors:\n",
    "  for comps in n_components:\n",
    "    for var in threshold:\n",
    "      scores = []\n",
    "      for train_index, test_index in kf.split(train):\n",
    "        selector = VarianceThreshold(var)\n",
    "        train_reduced = selector.fit_transform(train[train_index])\n",
    "        test_reduced = selector.transform(train[test_index])\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        train_scaled = scaler.fit_transform(train_reduced)\n",
    "        test_scaled = scaler.transform(test_reduced)\n",
    "        \n",
    "        sampler = RandomUnderSampler()\n",
    "        train_resampled, train_labels_resampled = sampler.fit_sample(train_scaled, train_labels[train_index])\n",
    "        \n",
    "        pca = PCA(n_components=comps)\n",
    "        train_PCA = pca.fit_transform(train_resampled)\n",
    "        test_PCA = pca.transform(test_scaled)\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors=n, n_jobs=-1)\n",
    "        knn.fit(train_PCA, train_labels_resampled)\n",
    "        preds = knn.predict(test_PCA)\n",
    "        \n",
    "        scores.append(f1_score(train_labels[test_index], preds, average='micro'))\n",
    "      scor=mean(scores)\n",
    "      if scor > sc:\n",
    "        sc=scor\n",
    "        thr = var\n",
    "        ncomp = comps\n",
    "        k = n\n",
    "       \n",
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "l8x3R177CF8x",
    "outputId": "d8839e43-5521-4942-db7e-3b84cb10098f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f1_micro score is  0.7644268774703558\n",
      "Optimized params are: threshold = 0, n_components = 12, kneighbours = 51\n"
     ]
    }
   ],
   "source": [
    "print(\"Best f1_micro score is \", sc)\n",
    "print(\"Optimized params are: threshold = {}, n_components = {}, kneighbours = {}\".format(thr, ncomp, k))\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "AXa0u55g2cpm",
    "outputId": "b62a7435-ce8a-4638-c52a-d771cb8dc8a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33485142 0.52794864 0.71093117 0.79514256 0.83866024 0.8724394\n",
      " 0.89832953 0.9199267  0.93668753 0.94816262 0.95840453 0.96693781]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAE9CAYAAABp+/tBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6af9fffb70>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evar = pca.explained_variance_ratio_\n",
    "cum_evar = np.cumsum(evar)\n",
    "print(cum_evar)\n",
    "plt.figure(1, figsize=(5, 5))\n",
    "plt.xlabel(\"Principal Component number\")\n",
    "plt.ylabel('Cumulative Variance')\n",
    "plt.plot(cum_evar, linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BGXAO_kDr5gQ"
   },
   "source": [
    "##f1_micro average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yy02dX7Qr69g"
   },
   "source": [
    "###Στάδια:\n",
    "1. KNeighbors Classifier\n",
    "\n",
    "###Επίδοση, βέλτιστη παράμετρος:\n",
    "Best f1_micro score is  0.7994071146245059\n",
    "\n",
    "Optimized params are: kneighbours = 11\n",
    "\n",
    "---\n",
    "###Στάδια: \n",
    "1.  Variance Threshold\n",
    "2. KNeighbors Classifier\n",
    "\n",
    "### Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_micro score is  0.7994071146245059\n",
    "\n",
    "Optimized params are: threshold = 0, kneighbours = 11\n",
    "\n",
    "---\n",
    "\n",
    "###Στάδια: \n",
    "1.  Variance Threshold\n",
    "2. Standard Scaler\n",
    "3. KNeighbors Classifier\n",
    "\n",
    "### Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_micro score is  **0.808102766798419**\n",
    "\n",
    "Optimized params are: threshold = 2000, kneighbours = 11\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "###Στάδια: \n",
    "1.  Variance Threshold\n",
    "2. Standard Scaler\n",
    "3. Random Oversampler\n",
    "3. KNeighbors Classifier\n",
    "\n",
    "### Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_micro score is  0.7559288537549407\n",
    "\n",
    "Optimized params are: threshold = 0, kneighbours = 1\n",
    "\n",
    "---\n",
    "\n",
    "###Στάδια: \n",
    "1.  Variance Threshold\n",
    "2. Standard Scaler\n",
    "3. Random Oversampler\n",
    "4. PCA\n",
    "3. KNeighbors Classifier\n",
    "\n",
    "### Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_micro score is  0.7867588932806324\n",
    "Optimized params are: threshold = 200, n_components = 3, kneighbours = 1\n",
    "\n",
    "Αξίζει εδώ να παρατηρήσουμε πως με 3 μόλις components εξηγούμε σχεδόν το 77% της πληροφορίας του dataset (όπως φαίνεται παραπάνω).\n",
    "\n",
    "---\n",
    "---\n",
    "###Θα κάνουμε τώρα Undersampling αντί για Oversampling\n",
    "\n",
    "###Στάδια: \n",
    "1.  Variance Threshold\n",
    "2. Standard Scaler\n",
    "3. Random **Under**sampler\n",
    "3. KNeighbors Classifier\n",
    "\n",
    "### Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_micro score is  0.7776679841897233\n",
    "\n",
    "Optimized params are: threshold = 0, kneighbours = 21\n",
    "\n",
    "---\n",
    "###Στάδια: \n",
    "1.  Variance Threshold\n",
    "2. Standard Scaler\n",
    "3. Random **Under**sampler\n",
    "4. PCA\n",
    "3. KNeighbors Classifier\n",
    "\n",
    "### Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_micro score is  0.7814229249011857\n",
    "\n",
    "Optimized params are: threshold = 2000, n_components =  7, kneighbours = 21\n",
    "\n",
    "---\n",
    "---\n",
    "###Θα χρησιμοποιήσουμε τώρα Min-max Scaler αντί για Standard Scaler\n",
    "\n",
    "###Στάδια:\n",
    "1. MinMax Scaler\n",
    "2. KNeighbors Classifier\n",
    "\n",
    "###Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_micro score is  0.7994071146245059\n",
    "\n",
    "Optimized params are: threshold = 0, kneighbours = 11\n",
    "\n",
    "---\n",
    "###Στάδια:\n",
    "1. MinMax Scaler\n",
    "2. Variance Threshold\n",
    "2. KNeighbors Classifier\n",
    "\n",
    "###Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_micro score is  0.7994071146245059\n",
    "\n",
    "Optimized params are: threshold = 0.05, kneighbours = 5\n",
    "\n",
    "---\n",
    "###Στάδια:\n",
    "1. MinMax Scaler\n",
    "2. Variance Threshold\n",
    "3. Random Oversampler\n",
    "2. KNeighbors Classifier\n",
    "\n",
    "###Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_micro score is  0.7733201581027668\n",
    "\n",
    "Optimized params are: threshold = 0.01, kneighbours = 1\n",
    "\n",
    "###Στάδια:\n",
    "1. MinMax Scaler\n",
    "2. Variance Threshold\n",
    "3. Random Oversampler\n",
    "4. PCA\n",
    "2. KNeighbors Classifier\n",
    "\n",
    "###Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_micro score is  0.7822134387351778\n",
    "\n",
    "Optimized params are: threshold = 0.0001, n_components = 7, kneighbours = 1\n",
    "\n",
    "---\n",
    "---\n",
    "###Δοκιμάζουμε και UnderSampling αντί για OverSampling\n",
    "###Στάδια:\n",
    "1. MinMax Scaler\n",
    "2. Variance Threshold\n",
    "3. Random **Under**sampler\n",
    "2. KNeighbors Classifier\n",
    "\n",
    "###Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_micro score is  0.7600790513833992\n",
    "\n",
    "Optimized params are: threshold = 0.001, kneighbours = 51\n",
    "\n",
    "---\n",
    "###Στάδια:\n",
    "1. MinMax Scaler\n",
    "2. Variance Threshold\n",
    "3. Random **Under**sampler\n",
    "4. PCA\n",
    "2. KNeighbors Classifier\n",
    "\n",
    "###Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_micro score is  0.7646245059288537\n",
    "\n",
    "Optimized params are: threshold = 0.0001, n_components = 12, kneighbours = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sHNnu8WdTzrS"
   },
   "source": [
    "##Βέλτιστη Αρχιτεκτονική"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sFp4NxyvRH6-"
   },
   "source": [
    "Συγκρίνοντας τους παραπάνω συνδυασμούς παρατηρούμε πως η βέλτιστη αρχιτεκτονική για τη μετρική **f1 micro average** φαίνεται να είναι:\n",
    "1. VarianceThreshold(var = 2000)\n",
    "2. StandardScaler()\n",
    "3. KNeighbors Classifier(n_neighbors = 11)\n",
    "\n",
    "η οποία δίνει score  0.808102766798419\n",
    "\n",
    "Για τη συγκεκριμένη αρχιτεκτονική θα εκτελέσουμε ένα στενότερο Grid Search (για να διαπιστώσουμε αν μπορεί να βελτιστοποιηθεί κι άλλο)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nCAjWyTk2YtX"
   },
   "outputs": [],
   "source": [
    "neighbors = [7, 9, 11, 13, 15]\n",
    "threshold = [1000, 1500, 2000, 2500,3000]\n",
    "k=0\n",
    "thr=0\n",
    "sc=0\n",
    "kf=KFold(n_splits=10)\n",
    "\n",
    "for n in neighbors:\n",
    "    for var in threshold:\n",
    "      scores = []\n",
    "      for train_index, test_index in kf.split(train):\n",
    "        selector = VarianceThreshold(var)\n",
    "        train_reduced = selector.fit_transform(train[train_index])\n",
    "        test_reduced = selector.transform(train[test_index])\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        train_scaled = scaler.fit_transform(train_reduced)\n",
    "        test_scaled = scaler.transform(test_reduced)\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors=n, n_jobs=-1)\n",
    "        knn.fit(train_scaled, train_labels[train_index])\n",
    "        preds = knn.predict(test_scaled)\n",
    "        scores.append(f1_score(train_labels[test_index], preds, average='micro'))\n",
    "        \n",
    "      scor=mean(scores)\n",
    "      #print(scor)\n",
    "      if scor > sc:\n",
    "        sc=scor\n",
    "        k = n\n",
    "        thr = var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "DVyHSfgkUygg",
    "outputId": "98f3320d-3f58-4257-8b09-7ae880924615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f1_micro score is  0.799209486166008\n",
      "Optimized params are: threshold = 2500, kneighbours = 13\n"
     ]
    }
   ],
   "source": [
    "print(\"Best f1_micro score is \", sc)\n",
    "print(\"Optimized params are: threshold = {}, kneighbours = {}\".format(thr, k))\n",
    "\n",
    "optimum_thr = thr\n",
    "optimum_k = k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ql5R8DsagJhV"
   },
   "source": [
    "Θα εφαρμόσουμε αυτό το μοντέλο για να κάνουμε fit σε όλο το training data και predict στο test data, τόσο για τον KNeighbors Classifier όσο και για τους Dummy Classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "colab_type": "code",
    "id": "3oBa9xAihTJC",
    "outputId": "93458912-9135-4eca-f21a-1e9f748ac00a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Συνολικός χρόνος fit και predict: 0.11300992965698242 seconds\n",
      "None\n",
      "[[ 3 15]\n",
      " [ 0 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.17      0.29        18\n",
      "           1       0.73      1.00      0.84        40\n",
      "\n",
      "   micro avg       0.74      0.74      0.74        58\n",
      "   macro avg       0.86      0.58      0.56        58\n",
      "weighted avg       0.81      0.74      0.67        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "selector = VarianceThreshold(optimum_thr)\n",
    "train_reduced = selector.fit_transform(train)\n",
    "test_reduced = selector.transform(test)\n",
    "        \n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train_reduced)\n",
    "test_scaled = scaler.transform(test_reduced)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=optimum_k, n_jobs=-1)\n",
    "\n",
    "knn.fit(train_scaled, train_labels)\n",
    "preds = knn.predict(test_scaled)\n",
    "print(print(\"Συνολικός χρόνος fit και predict: %s seconds\" % (time.time() - start_time)))\n",
    "\n",
    "print(confusion_matrix(test_labels, preds))\n",
    "print(classification_report(test_labels, preds))\n",
    "f1_micro_opt = {}\n",
    "f1_micro_opt['knn_optimized'] = f1_score(test_labels, preds, average = 'micro')\n",
    "diff = {}\n",
    "diff[\"knn\"] = f1_micro_opt['knn_optimized'] - f1_micro['knn_default']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZWP1IVoKBAM6"
   },
   "outputs": [],
   "source": [
    "model = uniform.fit(train_scaled, train_labels)\n",
    "model = constant_0.fit(train_scaled, train_labels)\n",
    "model = constant_1.fit(train_scaled, train_labels)\n",
    "model = most_frequent.fit(train_scaled, train_labels)\n",
    "model = stratified.fit(train_scaled, train_labels)\n",
    "\n",
    "#Uniform\n",
    "preds = uniform.predict(test_scaled)\n",
    "f1_micro_opt['uniform'] = f1_score(test_labels, preds, average = 'micro')\n",
    "diff['uniform'] = f1_micro_opt['uniform'] - f1_micro['uniform']\n",
    "#Constant 0\n",
    "preds = constant_0.predict(test)\n",
    "f1_micro_opt['constant_0'] = f1_score(test_labels, preds, average = 'micro')\n",
    "diff['constant_0'] = f1_micro_opt['constant_0'] - f1_micro['constant_0']\n",
    "\n",
    "#Constant 1\n",
    "preds = constant_1.predict(test)\n",
    "f1_micro_opt['constant_1'] = f1_score(test_labels, preds, average = 'micro')\n",
    "diff['constant_1'] = f1_micro_opt['constant_1'] - f1_micro['constant_1']\n",
    "\n",
    "#Most Frequent\n",
    "preds = most_frequent.predict(test)\n",
    "f1_micro_opt['most_frequent'] = f1_score(test_labels, preds, average = 'micro')\n",
    "diff['most_frequent'] = f1_micro_opt['most_frequent'] - f1_micro['most_frequent']\n",
    "\n",
    "#Stratified\n",
    "preds = stratified.predict(test)\n",
    "f1_micro_opt['stratified'] = f1_score(test_labels, preds, average = 'micro')\n",
    "diff['stratified'] = f1_micro_opt['stratified'] - f1_micro['stratified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "JFudWME1Avx7",
    "outputId": "15ab62d1-a0c4-472f-dd64-da31b34778f5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6af3c790b8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(len(f1_micro_opt)), list(f1_micro_opt.values()), align='center')\n",
    "plt.xticks(range(len(f1_micro_opt)), list(f1_micro_opt.keys()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "colab_type": "code",
    "id": "wLNa-H9uDhu1",
    "outputId": "f19faa6c-ff20-49f0-855d-2d9d82a629f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Μεταβολές στην επίδοση των ταξινομητών:\n",
      "\n",
      "knn 0.01724137931034475\n",
      "uniform 0.05172413793103453\n",
      "constant_0 0.0\n",
      "constant_1 0.0\n",
      "most_frequent 0.0\n",
      "stratified -0.06896551724137934\n"
     ]
    }
   ],
   "source": [
    "print(\"Μεταβολές στην επίδοση των ταξινομητών:\\n\")\n",
    "for header in diff:\n",
    "  print(header, diff[header])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CebAoY8_D5fI"
   },
   "source": [
    "Βλέπουμε λοιπόν πως η επίδοση του KNEighbors Classifier δεν έχει αυξηθεί πολύ, αλλά σύμφωνα με τη μεθοδολογία ήταν το καλύτερο που θα μπορούσαμε να κάνουμε.\n",
    "\n",
    "Όσον αφορά τους Dummy Classifiers, ούτε εδώ είχαμε μεγάλες μεταβολές, αλλά αυτό ήταν αναμενόμενο καθώς αυτοί **επιλέγουν τυχαία** οπότε η οποιαδήποτε μεταβολή οφείλεται στην τύχη. Για το λόγο αυτό, για τη μετρική f1 macro average **δε θα τους ξανακάνουμε fit**, αφού στην ουσία δεν έχει καμία διαφορά."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8fRJj_rmsWXy"
   },
   "source": [
    "##f1_macro average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3610
    },
    "colab_type": "code",
    "id": "jzlrFXf4sa9E",
    "outputId": "946f810b-7882-48cb-ceb1-6dc0c204d62c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "neighbors = [1, 5, 11, 21, 31, 41, 51]\n",
    "n_components = [3, 5, 7, 10, 12]\n",
    "threshold = [0, 0.0001, 0.001, 0.01, 0.05]\n",
    "\n",
    "thr=0\n",
    "ncomp=0\n",
    "k=0\n",
    "sc=0\n",
    "kf=KFold(n_splits=10)\n",
    "\n",
    "for n in neighbors:\n",
    "  for comps in n_components:\n",
    "    for var in threshold:\n",
    "      scores = []\n",
    "      for train_index, test_index in kf.split(train):\n",
    "        scaler = MinMaxScaler()\n",
    "        train_scaled = scaler.fit_transform(train[train_index])\n",
    "        test_scaled = scaler.transform(train[test_index])\n",
    "        \n",
    "        selector = VarianceThreshold(var)\n",
    "        train_reduced = selector.fit_transform(train_scaled)\n",
    "        test_reduced = selector.transform(test_scaled)\n",
    "        \n",
    "        sampler = RandomUnderSampler()\n",
    "        train_resampled, train_labels_resampled = sampler.fit_sample(train_reduced, train_labels[train_index])\n",
    "        \n",
    "        pca = PCA(n_components=comps)\n",
    "        train_PCA = pca.fit_transform(train_resampled)\n",
    "        test_PCA = pca.transform(test_reduced)\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors=n, n_jobs=-1)\n",
    "        knn.fit(train_resampled, train_labels_resampled)\n",
    "        preds = knn.predict(test_reduced)\n",
    "        scores.append(f1_score(train_labels[test_index], preds, average='macro'))\n",
    "      scor=mean(scores)\n",
    "      if scor > sc:\n",
    "        sc=scor\n",
    "        thr = var\n",
    "        ncomp = comps\n",
    "        k = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "o2jXuYflspL3",
    "outputId": "63f515b3-563f-4231-d715-0a813b442a81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f1_macro score is  0.6428407097856813\n",
      "Optimized params are: threshold = 0.001, n_components = 3, kneighbours = 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Best f1_macro score is \", sc)\n",
    "print(\"Optimized params are: threshold = {}, n_components = {}, kneighbours = {}\".format(thr, ncomp, k))\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kn2tUJLUsoHi"
   },
   "source": [
    "###Στάδια:\n",
    "1. KNeighbors Classifier\n",
    "\n",
    "###Επίδοση, βέλτιστη παράμετρος:\n",
    "Best f1_macro score is  0.624005102294576\n",
    "\n",
    "Optimized params are: kneighbours = 1\n",
    "\n",
    "---\n",
    "###Στάδια: \n",
    "1.  Variance Threshold\n",
    "2. KNeighbors Classifier\n",
    "\n",
    "### Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_macro score is  0.6417698613618917\n",
    "\n",
    "Optimized params are: threshold = 2000, kneighbours = 1\n",
    "\n",
    "---\n",
    "\n",
    "###Στάδια: \n",
    "1.  Variance Threshold\n",
    "2. Standard Scaler\n",
    "3. KNeighbors Classifier\n",
    "\n",
    "### Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_macro score is  0.6286971479567828\n",
    "\n",
    "Optimized params are: threshold = 0, kneighbours = 1\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "###Στάδια: \n",
    "1.  Variance Threshold\n",
    "2. Standard Scaler\n",
    "3. Random Oversampler\n",
    "3. KNeighbors Classifier\n",
    "\n",
    "### Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_macro score is  0.6286971479567828\n",
    "\n",
    "Optimized params are: threshold = 0, kneighbours = 1\n",
    "\n",
    "---\n",
    "\n",
    "###Στάδια: \n",
    "1.  Variance Threshold\n",
    "2. Standard Scaler\n",
    "3. Random Oversampler\n",
    "4. PCA\n",
    "3. KNeighbors Classifier\n",
    "\n",
    "### Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_macro score is  **0.6910510996085353**\n",
    "\n",
    "Optimized params are: threshold = 200, n_components = 3, kneighbours = 1\n",
    "\n",
    "---\n",
    "---\n",
    "###Θα κάνουμε τώρα Undersampling αντί για Oversampling\n",
    "\n",
    "###Στάδια: \n",
    "1.  Variance Threshold\n",
    "2. Standard Scaler\n",
    "3. Random **Under**sampler\n",
    "3. KNeighbors Classifier\n",
    "\n",
    "### Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_macro score is  0.6461775497301813\n",
    "\n",
    "Optimized params are: threshold = 2000, kneighbours = 41\n",
    "\n",
    "---\n",
    "###Στάδια: \n",
    "1.  Variance Threshold\n",
    "2. Standard Scaler\n",
    "3. Random **Under**sampler\n",
    "4. PCA\n",
    "3. KNeighbors Classifier\n",
    "\n",
    "### Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_macro score is  0.6452531447115987\n",
    "\n",
    "Optimized params are: threshold = 2000, n_components = 12, kneighbours = 21\n",
    "\n",
    "---\n",
    "---\n",
    "###Θα χρησιμοποιήσουμε τώρα Min-max Scaler αντί για Standard Scaler\n",
    "\n",
    "###Στάδια:\n",
    "1. MinMax Scaler\n",
    "2. KNeighbors Classifier\n",
    "\n",
    "###Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_macro score is  0.6411519601457681\n",
    "\n",
    "Optimized params are: kneighbours = 1\n",
    "\n",
    "---\n",
    "###Στάδια:\n",
    "1. MinMax Scaler\n",
    "2. Variance Threshold\n",
    "2. KNeighbors Classifier\n",
    "\n",
    "###Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_macro score is  0.6515759367539553\n",
    "\n",
    "Optimized params are: threshold = 0.01, kneighbours = 1\n",
    "\n",
    "---\n",
    "###Στάδια:\n",
    "1. MinMax Scaler\n",
    "2. Variance Threshold\n",
    "3. Random Oversampler\n",
    "2. KNeighbors Classifier\n",
    "\n",
    "###Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_macro score is  0.6515759367539553\n",
    "\n",
    "Optimized params are: threshold = 0.01, kneighbours = 1\n",
    "\n",
    "###Στάδια:\n",
    "1. MinMax Scaler\n",
    "2. Variance Threshold\n",
    "3. Random Oversampler\n",
    "4. PCA\n",
    "2. KNeighbors Classifier\n",
    "\n",
    "###Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_macro score is  0.6757562347287579\n",
    "\n",
    "Optimized params are: threshold = 0.0001, n_components = 10, kneighbours = 5\n",
    "\n",
    "---\n",
    "---\n",
    "###Δοκιμάζουμε και UnderSampling αντί για OverSampling\n",
    "###Στάδια:\n",
    "1. MinMax Scaler\n",
    "2. Variance Threshold\n",
    "3. Random **Under**sampler\n",
    "2. KNeighbors Classifier\n",
    "\n",
    "###Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "est f1_macro score is  0.644687516204544\n",
    "\n",
    "Optimized params are: threshold = 0, kneighbours = 21\n",
    "\n",
    "---\n",
    "###Στάδια:\n",
    "1. MinMax Scaler\n",
    "2. Variance Threshold\n",
    "3. Random **Under**sampler\n",
    "4. PCA\n",
    "2. KNeighbors Classifier\n",
    "\n",
    "###Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_macro score is  0.6337815585323331\n",
    "\n",
    "Optimized params are: threshold = 0.0001, n_components = 5, kneighbours = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SGq3_0dLClKI"
   },
   "source": [
    "##Βέλτιστη Αρχιτεκτονική\n",
    "###Στάδια: \n",
    "1.  Variance Threshold\n",
    "2. Standard Scaler\n",
    "3. Random Oversampler\n",
    "4. PCA\n",
    "3. KNeighbors Classifier\n",
    "\n",
    "### Επίδοση, βέλτιστες υπερπαράμετροι:\n",
    "Best f1_macro score is  **0.6910510996085353**\n",
    "\n",
    "Optimized params are: threshold = 200, n_components = 3, kneighbours = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jwbpDXspCcMa"
   },
   "outputs": [],
   "source": [
    "#Progressive GridSearch\n",
    "#Βελτιστοποιούμε ακόμα καλύτερα την αρχιτεκτονική\n",
    "\n",
    "threshold = [100, 150, 200, 2500, 300]\n",
    "n_components = [1,2,3,4]\n",
    "neighbors = [1,3,5]\n",
    "\n",
    "thr=0\n",
    "ncomp=0\n",
    "k=0\n",
    "sc=0\n",
    "kf=KFold(n_splits=10)\n",
    "\n",
    "for n in neighbors:\n",
    "  for comps in n_components:\n",
    "    for var in threshold:\n",
    "      scores = []\n",
    "      for train_index, test_index in kf.split(train):\n",
    "        selector = VarianceThreshold(var)\n",
    "        train_reduced = selector.fit_transform(train[train_index])\n",
    "        test_reduced = selector.transform(train[test_index])\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        train_scaled = scaler.fit_transform(train_reduced)\n",
    "        test_scaled = scaler.transform(test_reduced)\n",
    "        \n",
    "        sampler = RandomOverSampler()\n",
    "        train_resampled, train_labels_resampled = sampler.fit_sample(train_scaled, train_labels[train_index])\n",
    "        \n",
    "        pca = PCA(n_components=comps)\n",
    "        train_PCA = pca.fit_transform(train_resampled)\n",
    "        test_PCA = pca.transform(test_scaled)\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors=n, n_jobs=-1)\n",
    "        knn.fit(train_PCA, train_labels_resampled)\n",
    "        preds = knn.predict(test_PCA)\n",
    "        scores.append(f1_score(train_labels[test_index], preds, average='macro'))\n",
    "      \n",
    "      scor=mean(scores)\n",
    "      if scor > sc:\n",
    "        sc=scor\n",
    "        thr = var\n",
    "        ncomp = comps\n",
    "        k = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "A2wbToqg96ho",
    "outputId": "3c218825-9576-4003-8f78-21f2479b1b57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f1_micro score is  0.6893038255448286\n",
      "Optimized params are: threshold = 200, n_components = 4, kneighbours = 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Best f1_micro score is \", sc)\n",
    "print(\"Optimized params are: threshold = {}, n_components = {}, kneighbours = {}\".format(thr, ncomp, k))\n",
    "\n",
    "optimum_k = k\n",
    "optimum_thr = thr\n",
    "optimum_n = ncomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "id": "Or6wNHZEFFBi",
    "outputId": "ed269ffb-01da-4b50-e4cd-ed60424f8659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Συνολικός χρόνος fit και predict: 0.11875510215759277 seconds\n",
      "[[11  7]\n",
      " [11 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.61      0.55        18\n",
      "           1       0.81      0.72      0.76        40\n",
      "\n",
      "   micro avg       0.69      0.69      0.69        58\n",
      "   macro avg       0.65      0.67      0.66        58\n",
      "weighted avg       0.71      0.69      0.70        58\n",
      "\n",
      "\n",
      " Μεταβολή επίδοσης: 0.0768688024408849\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "selector = VarianceThreshold(optimum_thr)\n",
    "train_reduced = selector.fit_transform(train)\n",
    "test_reduced = selector.transform(test)\n",
    "        \n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train_reduced)\n",
    "test_scaled = scaler.transform(test_reduced)\n",
    "        \n",
    "sampler = RandomOverSampler()\n",
    "train_resampled, train_labels_resampled = sampler.fit_sample(train_scaled, train_labels)\n",
    "        \n",
    "pca = PCA(n_components=optimum_n)\n",
    "train_PCA = pca.fit_transform(train_resampled)\n",
    "test_PCA = pca.transform(test_scaled)\n",
    "        \n",
    "knn = KNeighborsClassifier(n_neighbors= optimum_k, n_jobs=-1)\n",
    "knn.fit(train_PCA, train_labels_resampled)\n",
    "preds = knn.predict(test_PCA)\n",
    "\n",
    "print(\"Συνολικός χρόνος fit και predict: %s seconds\" % (time.time() - start_time))\n",
    "print(confusion_matrix(test_labels, preds))\n",
    "print(classification_report(test_labels, preds))\n",
    "\n",
    "f1_macro['knn_optimized'] = f1_score(test_labels, preds, average = 'macro')\n",
    "print(\"\\n Μεταβολή επίδοσης:\", f1_macro['knn_optimized'] - f1_macro['knn_default'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "0gLCNakHGoSy",
    "outputId": "3132ca98-3137-4aa7-caca-a51ec00be83a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6af3c6dbe0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(len(f1_macro)), list(f1_macro.values()), align='center')\n",
    "plt.xticks(range(len(f1_macro)), list(f1_macro.keys()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ESIRXcQJGP6k"
   },
   "source": [
    "##Σχολιασμός\n",
    "Όσον αφορά τους χρόνους εκτέλεσης αυτοί δεν είναι πολύ μεγάλοι αφού το dataset μας είναι μικρό.\n",
    "\n",
    "Για τις μετρικές f1 micro και f1 marco βρήκαμε τη βέλτιστη αρχιτεκτονική σύμφωνα με τη μεθοδολογία και πράγματι οι επιδόσεις του κάθε μοντέλου αυξήθηκαν για τις μετρικές αυτές. \n",
    "\n",
    "Παρατηρούμε ότι για τον KNeighbors Classifier με τη βελτιστοποίηση της f1 micro βελτιστοποιήθηκαν και τα precision και recall (όπως ήταν αναμενόμενο). \n",
    "\n",
    "Για τη βέλτιστη μετρική f1 macro average το recall αυξήθηκε αλλά το precision μειώθηκε ελάχιστα."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Ασκ 1 - Small Dataset.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
